{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from src.CPPN1 import CPPN1\n",
    "from src.CPPN1 import CPPN1training\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"CPPNsquared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "num_steps = 5000000\n",
    "batch_size = 192\n",
    "learn_rate = 0.001\n",
    "momentum = 0.9\n",
    "num_channels = 3\n",
    "image_shape = (512, 644)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPPN1(\n",
      "  (fc1): Linear(in_features=2, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fce1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cppn1 = CPPN1()\n",
    "cppn1.load_state_dict = torch.load('Checkpoints/CPPN64.pt')\n",
    "print(cppn1)\n",
    "# feature maps trasfer learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(list(cppn1.children())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weights_initialized_randomly(model):\n",
    "#     for name, param in model.named_parameters():\n",
    "#         # Check if parameter is trainable and requires gradients\n",
    "#         if param.requires_grad:\n",
    "#             # If any parameter has non-zero values, it's not randomly initialized\n",
    "#             if torch.sum(param.data) != 0:\n",
    "#                 return False\n",
    "#     return True\n",
    "\n",
    "# print(weights_initialized_randomly(cppn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fce1.weight\n",
      "fce1.bias\n",
      "fc3.weight\n",
      "fc3.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in cppn1.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map spacial coordinates\n",
    "Updated ``name.endswith`` to ``(\"fc3.weight\"):`` so I'm only training on the last layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  0.,  4.,  0.],\n",
      "        [ 3.,  1.,  4.,  0.],\n",
      "        [ 3.,  2.,  4.,  0.],\n",
      "        [ 3.,  3.,  4.,  0.],\n",
      "        [ 3.,  4.,  4.,  0.],\n",
      "        [ 3.,  5.,  4.,  0.],\n",
      "        [ 3.,  6.,  4.,  0.],\n",
      "        [ 3.,  7.,  4.,  0.],\n",
      "        [ 3.,  8.,  4.,  0.],\n",
      "        [ 3.,  9.,  4.,  0.],\n",
      "        [ 3., 10.,  4.,  0.],\n",
      "        [ 3., 11.,  4.,  0.],\n",
      "        [ 3., 12.,  4.,  0.],\n",
      "        [ 3., 13.,  4.,  0.],\n",
      "        [ 3., 14.,  4.,  0.],\n",
      "        [ 3., 15.,  4.,  0.],\n",
      "        [ 3., 16.,  4.,  0.],\n",
      "        [ 3., 17.,  4.,  0.],\n",
      "        [ 3., 18.,  4.,  0.],\n",
      "        [ 3., 19.,  4.,  0.],\n",
      "        [ 3., 20.,  4.,  0.],\n",
      "        [ 3., 21.,  4.,  0.],\n",
      "        [ 3., 22.,  4.,  0.],\n",
      "        [ 3., 23.,  4.,  0.],\n",
      "        [ 3., 24.,  4.,  0.],\n",
      "        [ 3., 25.,  4.,  0.],\n",
      "        [ 3., 26.,  4.,  0.],\n",
      "        [ 3., 27.,  4.,  0.],\n",
      "        [ 3., 28.,  4.,  0.],\n",
      "        [ 3., 29.,  4.,  0.],\n",
      "        [ 3., 30.,  4.,  0.],\n",
      "        [ 3., 31.,  4.,  0.],\n",
      "        [ 3., 32.,  4.,  0.],\n",
      "        [ 3., 33.,  4.,  0.],\n",
      "        [ 3., 34.,  4.,  0.],\n",
      "        [ 3., 35.,  4.,  0.],\n",
      "        [ 3., 36.,  4.,  0.],\n",
      "        [ 3., 37.,  4.,  0.],\n",
      "        [ 3., 38.,  4.,  0.],\n",
      "        [ 3., 39.,  4.,  0.],\n",
      "        [ 3., 40.,  4.,  0.],\n",
      "        [ 3., 41.,  4.,  0.],\n",
      "        [ 3., 42.,  4.,  0.],\n",
      "        [ 3., 43.,  4.,  0.],\n",
      "        [ 3., 44.,  4.,  0.],\n",
      "        [ 3., 45.,  4.,  0.],\n",
      "        [ 3., 46.,  4.,  0.],\n",
      "        [ 3., 47.,  4.,  0.],\n",
      "        [ 3., 48.,  4.,  0.],\n",
      "        [ 3., 49.,  4.,  0.],\n",
      "        [ 3., 50.,  4.,  0.],\n",
      "        [ 3., 51.,  4.,  0.],\n",
      "        [ 3., 52.,  4.,  0.],\n",
      "        [ 3., 53.,  4.,  0.],\n",
      "        [ 3., 54.,  4.,  0.],\n",
      "        [ 3., 55.,  4.,  0.],\n",
      "        [ 3., 56.,  4.,  0.],\n",
      "        [ 3., 57.,  4.,  0.],\n",
      "        [ 3., 58.,  4.,  0.],\n",
      "        [ 3., 59.,  4.,  0.],\n",
      "        [ 3., 60.,  4.,  0.],\n",
      "        [ 3., 61.,  4.,  0.],\n",
      "        [ 3., 62.,  4.,  0.],\n",
      "        [ 3., 63.,  4.,  0.],\n",
      "        [ 3.,  0.,  4.,  1.],\n",
      "        [ 3.,  1.,  4.,  1.],\n",
      "        [ 3.,  2.,  4.,  1.],\n",
      "        [ 3.,  3.,  4.,  1.],\n",
      "        [ 3.,  4.,  4.,  1.],\n",
      "        [ 3.,  5.,  4.,  1.],\n",
      "        [ 3.,  6.,  4.,  1.],\n",
      "        [ 3.,  7.,  4.,  1.],\n",
      "        [ 3.,  8.,  4.,  1.],\n",
      "        [ 3.,  9.,  4.,  1.],\n",
      "        [ 3., 10.,  4.,  1.],\n",
      "        [ 3., 11.,  4.,  1.],\n",
      "        [ 3., 12.,  4.,  1.],\n",
      "        [ 3., 13.,  4.,  1.],\n",
      "        [ 3., 14.,  4.,  1.],\n",
      "        [ 3., 15.,  4.,  1.],\n",
      "        [ 3., 16.,  4.,  1.],\n",
      "        [ 3., 17.,  4.,  1.],\n",
      "        [ 3., 18.,  4.,  1.],\n",
      "        [ 3., 19.,  4.,  1.],\n",
      "        [ 3., 20.,  4.,  1.],\n",
      "        [ 3., 21.,  4.,  1.],\n",
      "        [ 3., 22.,  4.,  1.],\n",
      "        [ 3., 23.,  4.,  1.],\n",
      "        [ 3., 24.,  4.,  1.],\n",
      "        [ 3., 25.,  4.,  1.],\n",
      "        [ 3., 26.,  4.,  1.],\n",
      "        [ 3., 27.,  4.,  1.],\n",
      "        [ 3., 28.,  4.,  1.],\n",
      "        [ 3., 29.,  4.,  1.],\n",
      "        [ 3., 30.,  4.,  1.],\n",
      "        [ 3., 31.,  4.,  1.],\n",
      "        [ 3., 32.,  4.,  1.],\n",
      "        [ 3., 33.,  4.,  1.],\n",
      "        [ 3., 34.,  4.,  1.],\n",
      "        [ 3., 35.,  4.,  1.],\n",
      "        [ 3., 36.,  4.,  1.],\n",
      "        [ 3., 37.,  4.,  1.],\n",
      "        [ 3., 38.,  4.,  1.],\n",
      "        [ 3., 39.,  4.,  1.],\n",
      "        [ 3., 40.,  4.,  1.],\n",
      "        [ 3., 41.,  4.,  1.],\n",
      "        [ 3., 42.,  4.,  1.],\n",
      "        [ 3., 43.,  4.,  1.],\n",
      "        [ 3., 44.,  4.,  1.],\n",
      "        [ 3., 45.,  4.,  1.],\n",
      "        [ 3., 46.,  4.,  1.],\n",
      "        [ 3., 47.,  4.,  1.],\n",
      "        [ 3., 48.,  4.,  1.],\n",
      "        [ 3., 49.,  4.,  1.],\n",
      "        [ 3., 50.,  4.,  1.],\n",
      "        [ 3., 51.,  4.,  1.],\n",
      "        [ 3., 52.,  4.,  1.],\n",
      "        [ 3., 53.,  4.,  1.],\n",
      "        [ 3., 54.,  4.,  1.],\n",
      "        [ 3., 55.,  4.,  1.],\n",
      "        [ 3., 56.,  4.,  1.],\n",
      "        [ 3., 57.,  4.,  1.],\n",
      "        [ 3., 58.,  4.,  1.],\n",
      "        [ 3., 59.,  4.,  1.],\n",
      "        [ 3., 60.,  4.,  1.],\n",
      "        [ 3., 61.,  4.,  1.],\n",
      "        [ 3., 62.,  4.,  1.],\n",
      "        [ 3., 63.,  4.,  1.],\n",
      "        [ 3.,  0.,  4.,  2.],\n",
      "        [ 3.,  1.,  4.,  2.],\n",
      "        [ 3.,  2.,  4.,  2.],\n",
      "        [ 3.,  3.,  4.,  2.],\n",
      "        [ 3.,  4.,  4.,  2.],\n",
      "        [ 3.,  5.,  4.,  2.],\n",
      "        [ 3.,  6.,  4.,  2.],\n",
      "        [ 3.,  7.,  4.,  2.],\n",
      "        [ 3.,  8.,  4.,  2.],\n",
      "        [ 3.,  9.,  4.,  2.],\n",
      "        [ 3., 10.,  4.,  2.],\n",
      "        [ 3., 11.,  4.,  2.],\n",
      "        [ 3., 12.,  4.,  2.],\n",
      "        [ 3., 13.,  4.,  2.],\n",
      "        [ 3., 14.,  4.,  2.],\n",
      "        [ 3., 15.,  4.,  2.],\n",
      "        [ 3., 16.,  4.,  2.],\n",
      "        [ 3., 17.,  4.,  2.],\n",
      "        [ 3., 18.,  4.,  2.],\n",
      "        [ 3., 19.,  4.,  2.],\n",
      "        [ 3., 20.,  4.,  2.],\n",
      "        [ 3., 21.,  4.,  2.],\n",
      "        [ 3., 22.,  4.,  2.],\n",
      "        [ 3., 23.,  4.,  2.],\n",
      "        [ 3., 24.,  4.,  2.],\n",
      "        [ 3., 25.,  4.,  2.],\n",
      "        [ 3., 26.,  4.,  2.],\n",
      "        [ 3., 27.,  4.,  2.],\n",
      "        [ 3., 28.,  4.,  2.],\n",
      "        [ 3., 29.,  4.,  2.],\n",
      "        [ 3., 30.,  4.,  2.],\n",
      "        [ 3., 31.,  4.,  2.],\n",
      "        [ 3., 32.,  4.,  2.],\n",
      "        [ 3., 33.,  4.,  2.],\n",
      "        [ 3., 34.,  4.,  2.],\n",
      "        [ 3., 35.,  4.,  2.],\n",
      "        [ 3., 36.,  4.,  2.],\n",
      "        [ 3., 37.,  4.,  2.],\n",
      "        [ 3., 38.,  4.,  2.],\n",
      "        [ 3., 39.,  4.,  2.],\n",
      "        [ 3., 40.,  4.,  2.],\n",
      "        [ 3., 41.,  4.,  2.],\n",
      "        [ 3., 42.,  4.,  2.],\n",
      "        [ 3., 43.,  4.,  2.],\n",
      "        [ 3., 44.,  4.,  2.],\n",
      "        [ 3., 45.,  4.,  2.],\n",
      "        [ 3., 46.,  4.,  2.],\n",
      "        [ 3., 47.,  4.,  2.],\n",
      "        [ 3., 48.,  4.,  2.],\n",
      "        [ 3., 49.,  4.,  2.],\n",
      "        [ 3., 50.,  4.,  2.],\n",
      "        [ 3., 51.,  4.,  2.],\n",
      "        [ 3., 52.,  4.,  2.],\n",
      "        [ 3., 53.,  4.,  2.],\n",
      "        [ 3., 54.,  4.,  2.],\n",
      "        [ 3., 55.,  4.,  2.],\n",
      "        [ 3., 56.,  4.,  2.],\n",
      "        [ 3., 57.,  4.,  2.],\n",
      "        [ 3., 58.,  4.,  2.],\n",
      "        [ 3., 59.,  4.,  2.],\n",
      "        [ 3., 60.,  4.,  2.],\n",
      "        [ 3., 61.,  4.,  2.],\n",
      "        [ 3., 62.,  4.,  2.],\n",
      "        [ 3., 63.,  4.,  2.]], device='cuda:0')\n",
      "[[0.5, -1.0, 1.0, -1.0], [0.5, -0.9682539701461792, 1.0, -1.0], [0.5, -0.9365079402923584, 1.0, -1.0], [0.5, -0.9047619104385376, 1.0, -1.0], [0.5, -0.8730158805847168, 1.0, -1.0], [0.5, -0.841269850730896, 1.0, -1.0], [0.5, -0.8095238208770752, 1.0, -1.0], [0.5, -0.7777777910232544, 1.0, -1.0], [0.5, -0.7460317611694336, 1.0, -1.0], [0.5, -0.7142857313156128, 1.0, -1.0], [0.5, -0.682539701461792, 1.0, -1.0], [0.5, -0.6507936716079712, 1.0, -1.0], [0.5, -0.6190476417541504, 1.0, -1.0], [0.5, -0.5873016119003296, 1.0, -1.0], [0.5, -0.5555555820465088, 1.0, -1.0], [0.5, -0.523809552192688, 1.0, -1.0], [0.5, -0.4920634627342224, 1.0, -1.0], [0.5, -0.4603174328804016, 1.0, -1.0], [0.5, -0.4285714030265808, 1.0, -1.0], [0.5, -0.39682537317276, 1.0, -1.0], [0.5, -0.3650793433189392, 1.0, -1.0], [0.5, -0.3333333134651184, 1.0, -1.0], [0.5, -0.3015872836112976, 1.0, -1.0], [0.5, -0.2698412537574768, 1.0, -1.0], [0.5, -0.238095223903656, 1.0, -1.0], [0.5, -0.2063491940498352, 1.0, -1.0], [0.5, -0.1746031641960144, 1.0, -1.0], [0.5, -0.1428571343421936, 1.0, -1.0], [0.5, -0.1111111044883728, 1.0, -1.0], [0.5, -0.079365074634552, 1.0, -1.0], [0.5, -0.0476190447807312, 1.0, -1.0], [0.5, -0.0158730149269104, 1.0, -1.0], [0.5, 0.015873074531555176, 1.0, -1.0], [0.5, 0.04761910438537598, 1.0, -1.0], [0.5, 0.07936513423919678, 1.0, -1.0], [0.5, 0.11111116409301758, 1.0, -1.0], [0.5, 0.14285719394683838, 1.0, -1.0], [0.5, 0.17460322380065918, 1.0, -1.0], [0.5, 0.20634925365447998, 1.0, -1.0], [0.5, 0.23809528350830078, 1.0, -1.0], [0.5, 0.2698413133621216, 1.0, -1.0], [0.5, 0.3015873432159424, 1.0, -1.0], [0.5, 0.3333333730697632, 1.0, -1.0], [0.5, 0.365079402923584, 1.0, -1.0], [0.5, 0.3968254327774048, 1.0, -1.0], [0.5, 0.4285714626312256, 1.0, -1.0], [0.5, 0.4603174924850464, 1.0, -1.0], [0.5, 0.4920635223388672, 1.0, -1.0], [0.5, 0.523809552192688, 1.0, -1.0], [0.5, 0.5555555820465088, 1.0, -1.0], [0.5, 0.5873016119003296, 1.0, -1.0], [0.5, 0.6190476417541504, 1.0, -1.0], [0.5, 0.6507936716079712, 1.0, -1.0], [0.5, 0.682539701461792, 1.0, -1.0], [0.5, 0.7142857313156128, 1.0, -1.0], [0.5, 0.7460317611694336, 1.0, -1.0], [0.5, 0.7777777910232544, 1.0, -1.0], [0.5, 0.8095238208770752, 1.0, -1.0], [0.5, 0.841269850730896, 1.0, -1.0], [0.5, 0.8730158805847168, 1.0, -1.0], [0.5, 0.9047619104385376, 1.0, -1.0], [0.5, 0.9365079402923584, 1.0, -1.0], [0.5, 0.9682539701461792, 1.0, -1.0], [0.5, 1.0, 1.0, -1.0], [0.5, -1.0, 1.0, 0.0], [0.5, -0.9682539701461792, 1.0, 0.0], [0.5, -0.9365079402923584, 1.0, 0.0], [0.5, -0.9047619104385376, 1.0, 0.0], [0.5, -0.8730158805847168, 1.0, 0.0], [0.5, -0.841269850730896, 1.0, 0.0], [0.5, -0.8095238208770752, 1.0, 0.0], [0.5, -0.7777777910232544, 1.0, 0.0], [0.5, -0.7460317611694336, 1.0, 0.0], [0.5, -0.7142857313156128, 1.0, 0.0], [0.5, -0.682539701461792, 1.0, 0.0], [0.5, -0.6507936716079712, 1.0, 0.0], [0.5, -0.6190476417541504, 1.0, 0.0], [0.5, -0.5873016119003296, 1.0, 0.0], [0.5, -0.5555555820465088, 1.0, 0.0], [0.5, -0.523809552192688, 1.0, 0.0], [0.5, -0.4920634627342224, 1.0, 0.0], [0.5, -0.4603174328804016, 1.0, 0.0], [0.5, -0.4285714030265808, 1.0, 0.0], [0.5, -0.39682537317276, 1.0, 0.0], [0.5, -0.3650793433189392, 1.0, 0.0], [0.5, -0.3333333134651184, 1.0, 0.0], [0.5, -0.3015872836112976, 1.0, 0.0], [0.5, -0.2698412537574768, 1.0, 0.0], [0.5, -0.238095223903656, 1.0, 0.0], [0.5, -0.2063491940498352, 1.0, 0.0], [0.5, -0.1746031641960144, 1.0, 0.0], [0.5, -0.1428571343421936, 1.0, 0.0], [0.5, -0.1111111044883728, 1.0, 0.0], [0.5, -0.079365074634552, 1.0, 0.0], [0.5, -0.0476190447807312, 1.0, 0.0], [0.5, -0.0158730149269104, 1.0, 0.0], [0.5, 0.015873074531555176, 1.0, 0.0], [0.5, 0.04761910438537598, 1.0, 0.0], [0.5, 0.07936513423919678, 1.0, 0.0], [0.5, 0.11111116409301758, 1.0, 0.0], [0.5, 0.14285719394683838, 1.0, 0.0], [0.5, 0.17460322380065918, 1.0, 0.0], [0.5, 0.20634925365447998, 1.0, 0.0], [0.5, 0.23809528350830078, 1.0, 0.0], [0.5, 0.2698413133621216, 1.0, 0.0], [0.5, 0.3015873432159424, 1.0, 0.0], [0.5, 0.3333333730697632, 1.0, 0.0], [0.5, 0.365079402923584, 1.0, 0.0], [0.5, 0.3968254327774048, 1.0, 0.0], [0.5, 0.4285714626312256, 1.0, 0.0], [0.5, 0.4603174924850464, 1.0, 0.0], [0.5, 0.4920635223388672, 1.0, 0.0], [0.5, 0.523809552192688, 1.0, 0.0], [0.5, 0.5555555820465088, 1.0, 0.0], [0.5, 0.5873016119003296, 1.0, 0.0], [0.5, 0.6190476417541504, 1.0, 0.0], [0.5, 0.6507936716079712, 1.0, 0.0], [0.5, 0.682539701461792, 1.0, 0.0], [0.5, 0.7142857313156128, 1.0, 0.0], [0.5, 0.7460317611694336, 1.0, 0.0], [0.5, 0.7777777910232544, 1.0, 0.0], [0.5, 0.8095238208770752, 1.0, 0.0], [0.5, 0.841269850730896, 1.0, 0.0], [0.5, 0.8730158805847168, 1.0, 0.0], [0.5, 0.9047619104385376, 1.0, 0.0], [0.5, 0.9365079402923584, 1.0, 0.0], [0.5, 0.9682539701461792, 1.0, 0.0], [0.5, 1.0, 1.0, 0.0], [0.5, -1.0, 1.0, 1.0], [0.5, -0.9682539701461792, 1.0, 1.0], [0.5, -0.9365079402923584, 1.0, 1.0], [0.5, -0.9047619104385376, 1.0, 1.0], [0.5, -0.8730158805847168, 1.0, 1.0], [0.5, -0.841269850730896, 1.0, 1.0], [0.5, -0.8095238208770752, 1.0, 1.0], [0.5, -0.7777777910232544, 1.0, 1.0], [0.5, -0.7460317611694336, 1.0, 1.0], [0.5, -0.7142857313156128, 1.0, 1.0], [0.5, -0.682539701461792, 1.0, 1.0], [0.5, -0.6507936716079712, 1.0, 1.0], [0.5, -0.6190476417541504, 1.0, 1.0], [0.5, -0.5873016119003296, 1.0, 1.0], [0.5, -0.5555555820465088, 1.0, 1.0], [0.5, -0.523809552192688, 1.0, 1.0], [0.5, -0.4920634627342224, 1.0, 1.0], [0.5, -0.4603174328804016, 1.0, 1.0], [0.5, -0.4285714030265808, 1.0, 1.0], [0.5, -0.39682537317276, 1.0, 1.0], [0.5, -0.3650793433189392, 1.0, 1.0], [0.5, -0.3333333134651184, 1.0, 1.0], [0.5, -0.3015872836112976, 1.0, 1.0], [0.5, -0.2698412537574768, 1.0, 1.0], [0.5, -0.238095223903656, 1.0, 1.0], [0.5, -0.2063491940498352, 1.0, 1.0], [0.5, -0.1746031641960144, 1.0, 1.0], [0.5, -0.1428571343421936, 1.0, 1.0], [0.5, -0.1111111044883728, 1.0, 1.0], [0.5, -0.079365074634552, 1.0, 1.0], [0.5, -0.0476190447807312, 1.0, 1.0], [0.5, -0.0158730149269104, 1.0, 1.0], [0.5, 0.015873074531555176, 1.0, 1.0], [0.5, 0.04761910438537598, 1.0, 1.0], [0.5, 0.07936513423919678, 1.0, 1.0], [0.5, 0.11111116409301758, 1.0, 1.0], [0.5, 0.14285719394683838, 1.0, 1.0], [0.5, 0.17460322380065918, 1.0, 1.0], [0.5, 0.20634925365447998, 1.0, 1.0], [0.5, 0.23809528350830078, 1.0, 1.0], [0.5, 0.2698413133621216, 1.0, 1.0], [0.5, 0.3015873432159424, 1.0, 1.0], [0.5, 0.3333333730697632, 1.0, 1.0], [0.5, 0.365079402923584, 1.0, 1.0], [0.5, 0.3968254327774048, 1.0, 1.0], [0.5, 0.4285714626312256, 1.0, 1.0], [0.5, 0.4603174924850464, 1.0, 1.0], [0.5, 0.4920635223388672, 1.0, 1.0], [0.5, 0.523809552192688, 1.0, 1.0], [0.5, 0.5555555820465088, 1.0, 1.0], [0.5, 0.5873016119003296, 1.0, 1.0], [0.5, 0.6190476417541504, 1.0, 1.0], [0.5, 0.6507936716079712, 1.0, 1.0], [0.5, 0.682539701461792, 1.0, 1.0], [0.5, 0.7142857313156128, 1.0, 1.0], [0.5, 0.7460317611694336, 1.0, 1.0], [0.5, 0.7777777910232544, 1.0, 1.0], [0.5, 0.8095238208770752, 1.0, 1.0], [0.5, 0.841269850730896, 1.0, 1.0], [0.5, 0.8730158805847168, 1.0, 1.0], [0.5, 0.9047619104385376, 1.0, 1.0], [0.5, 0.9365079402923584, 1.0, 1.0], [0.5, 0.9682539701461792, 1.0, 1.0], [0.5, 1.0, 1.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "parameter_info = []\n",
    "fc1 = []\n",
    "full_coords = []\n",
    "full_weights = []\n",
    "layer_count = len(list(cppn1.children()))\n",
    "\n",
    "\n",
    "def normalize(tensor, axis):\n",
    "    if axis % 2 == 0:\n",
    "        max_vals = layer_count\n",
    "        min_vals = 0\n",
    "    else:\n",
    "        max_vals, _ = torch.max(tensor, dim=0)\n",
    "        min_vals, _ = torch.min(tensor, dim=0)\n",
    "\n",
    "    normalized_tensor = 2 * (tensor - min_vals) / (max_vals - min_vals) - 1\n",
    "    return normalized_tensor\n",
    "\n",
    "def spatial_coords(array, layer):\n",
    "\n",
    "    coords = []\n",
    "    row1 = []\n",
    "    row2 = []\n",
    "    for i in range(array.shape[0]):\n",
    "        row2.append([layer+1, i])\n",
    "    for i in range(array.shape[1]):\n",
    "        row1.append([layer, i])\n",
    "            \n",
    "    array = array.flatten(\"C\").tolist()\n",
    "    # print(array)\n",
    "    for i in row2:\n",
    "        for j in row1:\n",
    "            temp = []\n",
    "            temp.extend(j)\n",
    "            temp.extend(i)\n",
    "            coords.append((temp))\n",
    "    # coords_array = np.array(coords)\n",
    "    # coords_array.astype(int)\n",
    "    # output = np.column_stack((coords_array, array))\n",
    "\n",
    "    # print(len(output))\n",
    "    return coords, array\n",
    "            \n",
    "    # array.flatten()\n",
    "    # return np.stack((array, coords))\n",
    "\n",
    "index = 0\n",
    "for name, param in cppn1.named_parameters():\n",
    "    \n",
    "    # print(name)\n",
    "    if name.endswith(\"fc3.weight\"):\n",
    "        \n",
    "        # print(index)\n",
    "        # print(param)\n",
    "        temp_layer = param.detach().numpy() # need to learn more about gradients and why they are required\n",
    "        # print(temp_layer)\n",
    "\n",
    "        temp_coords, temp_weights = spatial_coords(temp_layer, 3)\n",
    "        temp_coords = torch.tensor(temp_coords, device=device, dtype=torch.float32)\n",
    "        normal = temp_coords\n",
    "        print(temp_coords)\n",
    "        for i in range(4):\n",
    "            # print(i)\n",
    "            normal[:,i] = normalize(temp_coords[:, i], i)\n",
    "            # normal = torch.nan_to_num(normal, nan = 0)\n",
    "        if index == 3:\n",
    "            # print(temp_coords)\n",
    "            print(normal)\n",
    "            # print(normal)\n",
    "        full_coords.extend(normal.tolist())\n",
    "        full_weights.extend(temp_weights)\n",
    "\n",
    "        index += 1\n",
    "        # print(fc1.shape[0])\n",
    "\n",
    "print(full_coords)\n",
    "\n",
    "# print(full_weights)\n",
    "    \n",
    "# layer1_coords, layer1_weights = spatial_coords(fce1, 2)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize =(12,8))\n",
    "# ax.scatter(range(len(full_weights)), full_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up CPPN_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPPN_squared(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "      super(CPPN_squared, self).__init__()\n",
    "\n",
    "      self.fc1 = nn.Linear(4, 16)\n",
    "\n",
    "      self.fc2 = nn.Linear(16, 64)\n",
    "      self.fce1 = nn.Linear(64, 64)\n",
    "      self.fce2 = nn.Linear(64, 16)\n",
    "\n",
    "      self.fc3 = nn.Linear(16, 1)     \n",
    "\n",
    "    #   self.init_weights()\n",
    "      \n",
    "    # def init_weights(self):\n",
    "    #   for m in self.modules():\n",
    "    #       if isinstance(m, nn.Linear):\n",
    "    #           # Initialize weights using Xavier initialization\n",
    "    #           init.xavier_normal_(m.weight)\n",
    "    #           # Initialize biases to zeros\n",
    "    #           init.constant_(m.bias, 0)\n",
    "    \n",
    "    # defines forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        # x = torch.sin(x)\n",
    "        x = F.relu(x)\n",
    "        # x = F.tanh(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        # x = torch.sin(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fce1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fce2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        # x = F.sigmoid(x)\n",
    "\n",
    "        # returns the output of layer 3 after activation\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPPN_squared = CPPN_squared()\n",
    "# wandb.watch(CPPN_squared)\n",
    "CPPN_squared.to(device)\n",
    "CPPN_squared.requires_grad_()\n",
    "\n",
    "# optimiser = torch.optim.SGD(cppn.parameters(), lr=learn_rate, momentum=momentum)\n",
    "optimiser = torch.optim.Adam(CPPN_squared.parameters(), lr=learn_rate)\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "# criterion = nn.L1Loss(reduction = \"mean\")\n",
    "# criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_minus1_to_1(tensor):\n",
    "    min_vals, _ = torch.min(tensor, dim=0)\n",
    "    max_vals, _ = torch.max(tensor, dim=0)\n",
    "    normalized_tensor = 2 * (tensor - min_vals) / (max_vals - min_vals) - 1\n",
    "    return normalized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.1486e-01, -1.0126e-01,  1.6890e-02, -4.9757e-02,  1.0856e-01,\n",
      "         9.4486e-02, -9.5382e-03,  3.2653e-02, -4.0045e-02,  2.3330e-02,\n",
      "         1.5321e-03, -1.1376e-01, -1.9972e-02, -8.9038e-02,  8.5516e-02,\n",
      "        -2.9499e-02, -6.9030e-02,  3.6684e-02, -7.0376e-02,  1.1722e-01,\n",
      "        -7.8740e-02, -1.0975e-01, -3.2090e-02,  9.6889e-03,  8.0951e-02,\n",
      "        -1.0712e-01, -1.1528e-01, -1.1934e-01, -1.1205e-01,  9.3543e-03,\n",
      "         1.0810e-01, -3.3055e-02,  1.2458e-01, -7.8355e-02,  1.1398e-01,\n",
      "         1.1633e-01,  4.8123e-02,  4.1446e-02, -9.1438e-02,  9.0600e-02,\n",
      "         2.4988e-03,  1.1379e-01, -5.8982e-02, -6.6981e-02, -5.2856e-02,\n",
      "        -1.1514e-01, -7.1593e-02,  1.2320e-01, -7.8257e-02,  7.0162e-02,\n",
      "        -7.0816e-02,  8.2255e-02, -9.6099e-02, -8.9011e-02,  2.7079e-02,\n",
      "        -1.2100e-01, -1.0627e-01, -8.7088e-02,  1.1338e-01,  7.3227e-02,\n",
      "         4.2031e-02, -5.9034e-02, -1.1249e-01, -1.1215e-01, -1.1954e-01,\n",
      "         2.6019e-02,  4.3218e-04,  3.1853e-02,  6.8005e-02,  2.7109e-02,\n",
      "        -6.0057e-02,  1.0931e-01,  4.9894e-02, -8.0747e-02,  4.0010e-02,\n",
      "        -9.4299e-02, -3.6027e-02,  3.8808e-02,  1.3990e-03,  5.4736e-02,\n",
      "         1.3068e-02, -1.1059e-02,  2.0241e-02, -1.0529e-01, -4.8816e-02,\n",
      "         1.2279e-01,  7.5459e-05, -1.2336e-01,  6.7827e-02,  3.1120e-02,\n",
      "         4.3097e-03,  8.3491e-02, -9.4353e-02, -1.0688e-01, -4.6066e-03,\n",
      "        -3.6511e-03, -2.9399e-03, -7.5010e-02,  2.3883e-02,  1.2000e-01,\n",
      "         5.6810e-02, -9.5026e-02, -1.1731e-01,  6.8786e-03,  9.0011e-02,\n",
      "        -2.9686e-02,  9.3914e-02, -7.2528e-02,  1.1410e-01, -6.8978e-02,\n",
      "        -4.2667e-02,  5.4982e-02,  6.8461e-03,  3.1606e-02,  1.2026e-01,\n",
      "        -1.1405e-01,  1.2161e-01,  3.2595e-02, -9.5924e-02, -5.0419e-02,\n",
      "         9.1543e-02, -1.2197e-01,  9.5997e-02, -1.1720e-01,  9.9103e-02,\n",
      "        -3.3031e-02,  2.3616e-02, -1.9280e-02, -4.1082e-02, -5.2239e-02,\n",
      "        -1.8791e-02, -8.6663e-02,  1.1442e-01,  6.7222e-03, -1.4322e-02,\n",
      "        -9.0661e-02,  5.4781e-02,  9.5250e-02, -3.6440e-02, -1.6244e-02,\n",
      "        -3.6731e-02,  5.4120e-02, -3.0901e-02, -4.3361e-03,  4.3071e-02,\n",
      "         9.9337e-02, -5.8831e-03,  4.5763e-03, -5.3436e-02,  4.4336e-02,\n",
      "         1.1812e-01,  7.4989e-02, -1.1160e-01, -6.0782e-02,  1.2300e-01,\n",
      "         1.1310e-01, -9.5182e-02, -3.7989e-03,  8.7189e-02, -1.2457e-01,\n",
      "         5.8042e-02,  9.5085e-02,  6.3479e-02,  7.1995e-03,  1.0738e-01,\n",
      "         4.8096e-02,  1.6475e-02,  9.2188e-02, -7.3217e-02,  7.1318e-02,\n",
      "        -6.7200e-02, -6.4488e-02,  7.0411e-02, -1.8760e-02, -3.2106e-02,\n",
      "        -4.8577e-02, -7.3524e-02, -3.9351e-02, -2.4455e-02,  1.2627e-02,\n",
      "         4.1325e-02, -1.0212e-01,  1.2236e-01, -9.2362e-02, -6.0687e-02,\n",
      "         3.3344e-02, -7.5252e-02,  1.0837e-01,  1.1764e-01, -9.0476e-02,\n",
      "         1.2899e-02,  2.9330e-02], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "normalized_coords_matrix = torch.tensor(full_coords, device=device, dtype=torch.float32)\n",
    "\n",
    "# Normalize the coordinates matrix along each column\n",
    "# normalized_coords_matrix = normalize_minus1_to_1(all_xy_coordinates)\n",
    "# print(normalized_coords_matrix)\n",
    "\n",
    "all_pixel_values = torch.tensor(full_weights, device=device, dtype=torch.float32)\n",
    "# all_pixel_values = (all_pixel_values + 1)/2\n",
    "# all_pixel_values = torch.unsqueeze(all_pixel_values, 0)\n",
    "print(all_pixel_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training and validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train, test = train_test_split(normalized_coords_matrix, test_size= 0.2, random_state=42)\n",
    "train_coords, val_coords, train_pixel_values, val_pixel_values = train_test_split(normalized_coords_matrix, all_pixel_values, test_size=0.1, random_state=42)\n",
    "# import math\n",
    "batch_size = int(batch_size * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5000, -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.9683,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.9365,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.9048,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.8730,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.8413,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.8095,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.7778,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.7460,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.7143,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.6825,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.6508,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.6190,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.5873,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.5556,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.5238,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.4921,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.4603,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.4286,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.3968,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.3651,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.3333,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.3016,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.2698,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.2381,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.2063,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.1746,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.1429,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.1111,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.0794,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.0476,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.0159,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.0159,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.0476,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.0794,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.1111,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.1429,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.1746,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.2063,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.2381,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.2698,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.3016,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.3333,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.3651,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.3968,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.4286,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.4603,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.4921,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.5238,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.5556,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.5873,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.6190,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.6508,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.6825,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.7143,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.7460,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.7778,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.8095,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.8413,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.8730,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.9048,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.9365,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.9683,  1.0000, -1.0000],\n",
      "        [ 0.5000,  1.0000,  1.0000, -1.0000],\n",
      "        [ 0.5000, -1.0000,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.9683,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.9365,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.9048,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.8730,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.8413,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.8095,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.7778,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.7460,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.7143,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.6825,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.6508,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.6190,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.5873,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.5556,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.5238,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.4921,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.4603,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.4286,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.3968,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.3651,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.3333,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.3016,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.2698,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.2381,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.2063,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.1746,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.1429,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.1111,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.0794,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.0476,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.0159,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.0159,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.0476,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.0794,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.1111,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.1429,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.1746,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.2063,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.2381,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.2698,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.3016,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.3333,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.3651,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.3968,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.4286,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.4603,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.4921,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.5238,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.5556,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.5873,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.6190,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.6508,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.6825,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.7143,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.7460,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.7778,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.8095,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.8413,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.8730,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.9048,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.9365,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.9683,  1.0000,  0.0000],\n",
      "        [ 0.5000,  1.0000,  1.0000,  0.0000],\n",
      "        [ 0.5000, -1.0000,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.9683,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.9365,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.9048,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.8730,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.8413,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.8095,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.7778,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.7460,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.7143,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.6825,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.6508,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.6190,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.5873,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.5556,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.5238,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.4921,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.4603,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.4286,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.3968,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.3651,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.3333,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.3016,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.2698,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.2381,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.2063,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.1746,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.1429,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.1111,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.0794,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.0476,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.0159,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0159,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0476,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0794,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.1111,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.1429,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.1746,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.2063,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.2381,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.2698,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.3016,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.3333,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.3651,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.3968,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.4286,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.4603,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.4921,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.5238,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.5556,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.5873,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.6190,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.6508,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.6825,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.7143,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.7460,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.7778,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.8095,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.8413,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.8730,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.9048,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.9365,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.9683,  1.0000,  1.0000],\n",
      "        [ 0.5000,  1.0000,  1.0000,  1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(normalized_coords_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 0.000\n",
      "Validation - Step 0, loss 0.013\n",
      "step 10000, loss 0.003\n",
      "Validation - Step 10000, loss 0.016\n",
      "step 20000, loss 0.003\n",
      "Validation - Step 20000, loss 0.020\n",
      "step 30000, loss 0.002\n",
      "Validation - Step 30000, loss 0.018\n",
      "step 40000, loss 0.002\n",
      "Validation - Step 40000, loss 0.040\n",
      "step 50000, loss 0.002\n",
      "Validation - Step 50000, loss 0.090\n",
      "step 60000, loss 0.001\n",
      "Validation - Step 60000, loss 0.086\n",
      "step 70000, loss 0.001\n",
      "Validation - Step 70000, loss 0.029\n",
      "step 80000, loss 0.001\n",
      "Validation - Step 80000, loss 0.019\n",
      "step 90000, loss 0.001\n",
      "Validation - Step 90000, loss 0.022\n",
      "step 100000, loss 0.001\n",
      "Validation - Step 100000, loss 0.020\n",
      "step 110000, loss 0.001\n",
      "Validation - Step 110000, loss 0.021\n",
      "step 120000, loss 0.001\n",
      "Validation - Step 120000, loss 0.020\n",
      "step 130000, loss 0.001\n",
      "Validation - Step 130000, loss 0.025\n",
      "step 140000, loss 0.000\n",
      "Validation - Step 140000, loss 0.029\n",
      "step 150000, loss 0.000\n",
      "Validation - Step 150000, loss 0.035\n",
      "step 160000, loss 0.000\n",
      "Validation - Step 160000, loss 0.037\n",
      "step 170000, loss 0.000\n",
      "Validation - Step 170000, loss 0.041\n",
      "step 180000, loss 0.000\n",
      "Validation - Step 180000, loss 0.049\n",
      "step 190000, loss 0.000\n",
      "Validation - Step 190000, loss 0.047\n",
      "step 200000, loss 0.000\n",
      "Validation - Step 200000, loss 0.040\n",
      "step 210000, loss 0.000\n",
      "Validation - Step 210000, loss 0.042\n",
      "step 220000, loss 0.000\n",
      "Validation - Step 220000, loss 0.030\n",
      "step 230000, loss 0.000\n",
      "Validation - Step 230000, loss 0.025\n",
      "step 240000, loss 0.000\n",
      "Validation - Step 240000, loss 0.027\n",
      "step 250000, loss 0.000\n",
      "Validation - Step 250000, loss 0.027\n",
      "step 260000, loss 0.000\n",
      "Validation - Step 260000, loss 0.027\n",
      "step 270000, loss 0.000\n",
      "Validation - Step 270000, loss 0.032\n",
      "step 280000, loss 0.000\n",
      "Validation - Step 280000, loss 0.033\n",
      "step 290000, loss 0.000\n",
      "Validation - Step 290000, loss 0.019\n",
      "step 300000, loss 0.000\n",
      "Validation - Step 300000, loss 0.020\n",
      "step 310000, loss 0.000\n",
      "Validation - Step 310000, loss 0.019\n",
      "step 320000, loss 0.000\n",
      "Validation - Step 320000, loss 0.018\n",
      "step 330000, loss 0.000\n",
      "Validation - Step 330000, loss 0.022\n",
      "step 340000, loss 0.000\n",
      "Validation - Step 340000, loss 0.021\n",
      "step 350000, loss 0.000\n",
      "Validation - Step 350000, loss 0.021\n",
      "step 360000, loss 0.000\n",
      "Validation - Step 360000, loss 0.020\n",
      "step 370000, loss 0.000\n",
      "Validation - Step 370000, loss 0.019\n",
      "step 380000, loss 0.000\n",
      "Validation - Step 380000, loss 0.018\n",
      "step 390000, loss 0.000\n",
      "Validation - Step 390000, loss 0.018\n",
      "step 400000, loss 0.000\n",
      "Validation - Step 400000, loss 0.015\n",
      "step 410000, loss 0.000\n",
      "Validation - Step 410000, loss 0.024\n",
      "step 420000, loss 0.000\n",
      "Validation - Step 420000, loss 0.016\n",
      "step 430000, loss 0.000\n",
      "Validation - Step 430000, loss 0.016\n",
      "step 440000, loss 0.000\n",
      "Validation - Step 440000, loss 0.017\n",
      "step 450000, loss 0.000\n",
      "Validation - Step 450000, loss 0.016\n",
      "step 460000, loss 0.000\n",
      "Validation - Step 460000, loss 0.015\n",
      "step 470000, loss 0.000\n",
      "Validation - Step 470000, loss 0.014\n",
      "step 480000, loss 0.000\n",
      "Validation - Step 480000, loss 0.013\n",
      "step 490000, loss 0.000\n",
      "Validation - Step 490000, loss 0.013\n",
      "step 500000, loss 0.000\n",
      "Validation - Step 500000, loss 0.012\n",
      "step 510000, loss 0.000\n",
      "Validation - Step 510000, loss 0.011\n",
      "step 520000, loss 0.000\n",
      "Validation - Step 520000, loss 0.011\n",
      "step 530000, loss 0.000\n",
      "Validation - Step 530000, loss 0.011\n",
      "step 540000, loss 0.000\n",
      "Validation - Step 540000, loss 0.011\n",
      "step 550000, loss 0.000\n",
      "Validation - Step 550000, loss 0.011\n",
      "step 560000, loss 0.000\n",
      "Validation - Step 560000, loss 0.012\n",
      "step 570000, loss 0.000\n",
      "Validation - Step 570000, loss 0.017\n",
      "step 580000, loss 0.000\n",
      "Validation - Step 580000, loss 0.013\n",
      "step 590000, loss 0.000\n",
      "Validation - Step 590000, loss 0.022\n",
      "step 600000, loss 0.000\n",
      "Validation - Step 600000, loss 0.026\n",
      "step 610000, loss 0.000\n",
      "Validation - Step 610000, loss 0.019\n",
      "step 620000, loss 0.000\n",
      "Validation - Step 620000, loss 0.018\n",
      "step 630000, loss 0.000\n",
      "Validation - Step 630000, loss 0.018\n",
      "step 640000, loss 0.000\n",
      "Validation - Step 640000, loss 0.014\n",
      "step 650000, loss 0.000\n",
      "Validation - Step 650000, loss 0.014\n",
      "step 660000, loss 0.000\n",
      "Validation - Step 660000, loss 0.016\n",
      "step 670000, loss 0.000\n",
      "Validation - Step 670000, loss 0.016\n",
      "step 680000, loss 0.000\n",
      "Validation - Step 680000, loss 0.011\n",
      "step 690000, loss 0.000\n",
      "Validation - Step 690000, loss 0.013\n",
      "step 700000, loss 0.000\n",
      "Validation - Step 700000, loss 0.011\n",
      "step 710000, loss 0.000\n",
      "Validation - Step 710000, loss 0.011\n",
      "step 720000, loss 0.000\n",
      "Validation - Step 720000, loss 0.012\n",
      "step 730000, loss 0.000\n",
      "Validation - Step 730000, loss 0.011\n",
      "step 740000, loss 0.000\n",
      "Validation - Step 740000, loss 0.010\n",
      "step 750000, loss 0.000\n",
      "Validation - Step 750000, loss 0.010\n",
      "step 760000, loss 0.000\n",
      "Validation - Step 760000, loss 0.009\n",
      "step 770000, loss 0.000\n",
      "Validation - Step 770000, loss 0.010\n",
      "step 780000, loss 0.000\n",
      "Validation - Step 780000, loss 0.009\n",
      "step 790000, loss 0.000\n",
      "Validation - Step 790000, loss 0.010\n",
      "step 800000, loss 0.000\n",
      "Validation - Step 800000, loss 0.010\n",
      "step 810000, loss 0.000\n",
      "Validation - Step 810000, loss 0.010\n",
      "step 820000, loss 0.000\n",
      "Validation - Step 820000, loss 0.009\n",
      "step 830000, loss 0.000\n",
      "Validation - Step 830000, loss 0.010\n",
      "step 840000, loss 0.000\n",
      "Validation - Step 840000, loss 0.010\n",
      "step 850000, loss 0.000\n",
      "Validation - Step 850000, loss 0.010\n",
      "step 860000, loss 0.000\n",
      "Validation - Step 860000, loss 0.010\n",
      "step 870000, loss 0.000\n",
      "Validation - Step 870000, loss 0.009\n",
      "step 880000, loss 0.000\n",
      "Validation - Step 880000, loss 0.009\n",
      "step 890000, loss 0.000\n",
      "Validation - Step 890000, loss 0.009\n",
      "step 900000, loss 0.000\n",
      "Validation - Step 900000, loss 0.012\n",
      "step 910000, loss 0.000\n",
      "Validation - Step 910000, loss 0.012\n",
      "step 920000, loss 0.000\n",
      "Validation - Step 920000, loss 0.012\n",
      "step 930000, loss 0.000\n",
      "Validation - Step 930000, loss 0.011\n",
      "step 940000, loss 0.000\n",
      "Validation - Step 940000, loss 0.012\n",
      "step 950000, loss 0.000\n",
      "Validation - Step 950000, loss 0.012\n",
      "step 960000, loss 0.000\n",
      "Validation - Step 960000, loss 0.013\n",
      "step 970000, loss 0.000\n",
      "Validation - Step 970000, loss 0.013\n",
      "step 980000, loss 0.000\n",
      "Validation - Step 980000, loss 0.011\n",
      "step 990000, loss 0.000\n",
      "Validation - Step 990000, loss 0.011\n",
      "step 1000000, loss 0.000\n",
      "Validation - Step 1000000, loss 0.011\n",
      "step 1010000, loss 0.000\n",
      "Validation - Step 1010000, loss 0.009\n",
      "step 1020000, loss 0.000\n",
      "Validation - Step 1020000, loss 0.010\n",
      "step 1030000, loss 0.000\n",
      "Validation - Step 1030000, loss 0.010\n",
      "step 1040000, loss 0.000\n",
      "Validation - Step 1040000, loss 0.017\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m approx_pixel_values \u001b[38;5;241m=\u001b[39m CPPN_squared(training_coords_batch)\n\u001b[0;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(approx_pixel_values, pixel_values_batch)\n\u001b[1;32m---> 24\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     25\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m display_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_coords = normalized_coords_matrix.shape[0]\n",
    "coord_indexes = list(range(0, num_coords))\n",
    "losses = []\n",
    "img_list = []\n",
    "running_loss = 0.0\n",
    "best_loss = 10000000\n",
    "best_val_loss = 10000000\n",
    "display_num = 10000\n",
    "\n",
    "for i in range(num_steps):\n",
    "    optimiser.zero_grad()\n",
    "    CPPN_squared.zero_grad()\n",
    "\n",
    "    training_batch_indexes = torch.tensor(np.array(random.sample(range(0, train_coords.shape[0]), batch_size)))\n",
    "    \n",
    "    training_coords_batch = normalized_coords_matrix[training_batch_indexes]\n",
    "    \n",
    "    pixel_values_batch = train_pixel_values[training_batch_indexes]\n",
    "    pixel_values_batch = pixel_values_batch.unsqueeze(1)\n",
    "    \n",
    "    approx_pixel_values = CPPN_squared(training_coords_batch)\n",
    "    \n",
    "    loss = criterion(approx_pixel_values, pixel_values_batch)\n",
    "    running_loss += loss.item()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if i % display_num == 0:\n",
    "        if running_loss < best_loss:\n",
    "            best_loss = running_loss\n",
    "            torch.save(CPPN_squared.state_dict(), 'Checkpoints/CPPN2model.pt')\n",
    "        print(f'step {i}, loss {running_loss/display_num:.5f}')\n",
    "        # wandb.log({\"loss\": loss.item()})\n",
    "        running_loss = 0.0\n",
    "\n",
    "        #validation loop\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            val_output = CPPN_squared(val_coords)\n",
    "            val_loss += criterion(val_output,val_pixel_values.unsqueeze(1)).item()\n",
    "\n",
    "                \n",
    "            print(f'Validation - Step {i}, loss {val_loss:.5f}')\n",
    "            # wandb.log({\"val_loss\": val_loss})\n",
    "\n",
    "            \n",
    "    #Update model\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    # wandb.log({\"final_weights\": CPPN_squared.state_dict()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([192])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    torch.set_printoptions(profile=\"full\")\n",
    "    prediction = CPPN_squared(normalized_coords_matrix)\n",
    "    prediction = prediction.flatten(0)\n",
    "    # prediction = prediction * 2 - 1\n",
    "    print(prediction.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.1486e-01, -1.0126e-01,  1.6890e-02, -4.9757e-02,  1.0856e-01,\n",
      "         9.4486e-02, -9.5382e-03,  3.2653e-02, -4.0045e-02,  2.3330e-02,\n",
      "         1.5321e-03, -1.1376e-01, -1.9972e-02, -8.9038e-02,  8.5516e-02,\n",
      "        -2.9499e-02, -6.9030e-02,  3.6684e-02, -7.0376e-02,  1.1722e-01,\n",
      "        -7.8740e-02, -1.0975e-01, -3.2090e-02,  9.6889e-03,  8.0951e-02,\n",
      "        -1.0712e-01, -1.1528e-01, -1.1934e-01, -1.1205e-01,  9.3543e-03,\n",
      "         1.0810e-01, -3.3055e-02,  1.2458e-01, -7.8355e-02,  1.1398e-01,\n",
      "         1.1633e-01,  4.8123e-02,  4.1446e-02, -9.1438e-02,  9.0600e-02,\n",
      "         2.4988e-03,  1.1379e-01, -5.8982e-02, -6.6981e-02, -5.2856e-02,\n",
      "        -1.1514e-01, -7.1593e-02,  1.2320e-01, -7.8257e-02,  7.0162e-02,\n",
      "        -7.0816e-02,  8.2255e-02, -9.6099e-02, -8.9011e-02,  2.7079e-02,\n",
      "        -1.2100e-01, -1.0627e-01, -8.7088e-02,  1.1338e-01,  7.3227e-02,\n",
      "         4.2031e-02, -5.9034e-02, -1.1249e-01, -1.1215e-01, -1.1954e-01,\n",
      "         2.6019e-02,  4.3218e-04,  3.1853e-02,  6.8005e-02,  2.7109e-02,\n",
      "        -6.0057e-02,  1.0931e-01,  4.9894e-02, -8.0747e-02,  4.0010e-02,\n",
      "        -9.4299e-02, -3.6027e-02,  3.8808e-02,  1.3990e-03,  5.4736e-02,\n",
      "         1.3068e-02, -1.1059e-02,  2.0241e-02, -1.0529e-01, -4.8816e-02,\n",
      "         1.2279e-01,  7.5459e-05, -1.2336e-01,  6.7827e-02,  3.1120e-02,\n",
      "         4.3097e-03,  8.3491e-02, -9.4353e-02, -1.0688e-01, -4.6066e-03,\n",
      "        -3.6511e-03, -2.9399e-03, -7.5010e-02,  2.3883e-02,  1.2000e-01,\n",
      "         5.6810e-02, -9.5026e-02, -1.1731e-01,  6.8786e-03,  9.0011e-02,\n",
      "        -2.9686e-02,  9.3914e-02, -7.2528e-02,  1.1410e-01, -6.8978e-02,\n",
      "        -4.2667e-02,  5.4982e-02,  6.8461e-03,  3.1606e-02,  1.2026e-01,\n",
      "        -1.1405e-01,  1.2161e-01,  3.2595e-02, -9.5924e-02, -5.0419e-02,\n",
      "         9.1543e-02, -1.2197e-01,  9.5997e-02, -1.1720e-01,  9.9103e-02,\n",
      "        -3.3031e-02,  2.3616e-02, -1.9280e-02, -4.1082e-02, -5.2239e-02,\n",
      "        -1.8791e-02, -8.6663e-02,  1.1442e-01,  6.7222e-03, -1.4322e-02,\n",
      "        -9.0661e-02,  5.4781e-02,  9.5250e-02, -3.6440e-02, -1.6244e-02,\n",
      "        -3.6731e-02,  5.4120e-02, -3.0901e-02, -4.3361e-03,  4.3071e-02,\n",
      "         9.9337e-02, -5.8831e-03,  4.5763e-03, -5.3436e-02,  4.4336e-02,\n",
      "         1.1812e-01,  7.4989e-02, -1.1160e-01, -6.0782e-02,  1.2300e-01,\n",
      "         1.1310e-01, -9.5182e-02, -3.7989e-03,  8.7189e-02, -1.2457e-01,\n",
      "         5.8042e-02,  9.5085e-02,  6.3479e-02,  7.1995e-03,  1.0738e-01,\n",
      "         4.8096e-02,  1.6475e-02,  9.2188e-02, -7.3217e-02,  7.1318e-02,\n",
      "        -6.7200e-02, -6.4488e-02,  7.0411e-02, -1.8760e-02, -3.2106e-02,\n",
      "        -4.8577e-02, -7.3524e-02, -3.9351e-02, -2.4455e-02,  1.2627e-02,\n",
      "         4.1325e-02, -1.0212e-01,  1.2236e-01, -9.2362e-02, -6.0687e-02,\n",
      "         3.3344e-02, -7.5252e-02,  1.0837e-01,  1.1764e-01, -9.0476e-02,\n",
      "         1.2899e-02,  2.9330e-02], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(all_pixel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'target')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharey=True, figsize = (15, 6))\n",
    "# ax[0].set_ylim([0.1, 0.9])\n",
    "x_values = np.arange(len(prediction.cpu().numpy()))\n",
    "\n",
    "ax[0].scatter(x_values, prediction.cpu().numpy(), marker='o', s=2)\n",
    "ax[0].set_title(\"prediction\")\n",
    "ax[1].scatter(x_values, all_pixel_values.cpu().numpy(), marker='o', s=2)\n",
    "ax[1].set_title(\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly updated ``name.endswith`` to ``(\"fc3.weight\"):`` so I'm only replacing the last layer with new weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "tensor([[-0.0676,  0.1181, -0.0975,  0.0237,  0.0325, -0.1136,  0.0788,  0.0881,\n",
      "          0.0425,  0.0520,  0.1205,  0.0186,  0.1189,  0.0080, -0.0657,  0.0966,\n",
      "          0.0088, -0.0301,  0.0487,  0.0226, -0.0681,  0.0628,  0.1166, -0.0881,\n",
      "         -0.0590,  0.1224, -0.0920, -0.1196, -0.0928,  0.0252,  0.0097, -0.0951,\n",
      "         -0.1053,  0.0836,  0.0080, -0.0905, -0.0315,  0.1137, -0.0184,  0.1149,\n",
      "         -0.1234, -0.0895, -0.0599, -0.0743, -0.1142, -0.1165,  0.1231, -0.0029,\n",
      "          0.0177, -0.0697,  0.0572, -0.1060, -0.0406,  0.0492,  0.0422, -0.0309,\n",
      "         -0.0908,  0.0344, -0.0173, -0.1117, -0.0481, -0.1085, -0.0095, -0.1201],\n",
      "        [ 0.0899,  0.1082,  0.1245,  0.0991, -0.0377,  0.0941,  0.0954,  0.0022,\n",
      "         -0.1123, -0.0021, -0.0152,  0.1158,  0.0719, -0.0049, -0.0627,  0.1072,\n",
      "         -0.1178, -0.0542,  0.0918, -0.1103,  0.0036, -0.0528, -0.0480, -0.1065,\n",
      "          0.0098,  0.0432, -0.0353, -0.0095,  0.1152,  0.0555, -0.0478,  0.0916,\n",
      "         -0.0323,  0.0010,  0.0396, -0.0745,  0.0967,  0.1232, -0.0048,  0.0048,\n",
      "          0.0131, -0.0590, -0.0809, -0.0785, -0.0666,  0.1147, -0.0498, -0.0297,\n",
      "         -0.0878, -0.0173,  0.1191, -0.0229,  0.0714,  0.0145,  0.1144,  0.0330,\n",
      "         -0.0422,  0.0845, -0.1040,  0.0711, -0.0321,  0.0315, -0.0397, -0.0885],\n",
      "        [ 0.0724,  0.1067, -0.0880,  0.0350,  0.0495, -0.0743, -0.0153,  0.0926,\n",
      "         -0.0722, -0.1124,  0.0275, -0.0718, -0.0726,  0.1176,  0.1133, -0.0793,\n",
      "          0.0665, -0.1098, -0.0871,  0.0584,  0.0337, -0.0521,  0.0416, -0.0029,\n",
      "         -0.1013, -0.1007, -0.0958,  0.0443, -0.0185,  0.0759,  0.0076,  0.1220,\n",
      "          0.1210, -0.1234,  0.0397, -0.1221,  0.0274, -0.0784,  0.1115,  0.1013,\n",
      "          0.0891, -0.0905,  0.0162, -0.1138, -0.0683, -0.0124,  0.0836,  0.1795,\n",
      "          0.2831,  0.2587, -0.0810, -0.0763, -0.0194,  0.0109,  0.0178,  0.0072,\n",
      "          0.0021,  0.0064, -0.0245, -0.0553, -0.0862, -0.0809, -0.0517, -0.0699]],\n",
      "       device='cuda:0')\n",
      "fc3.weight replacement complete\n"
     ]
    }
   ],
   "source": [
    "# prediction.mul_(2).sub_(1)\n",
    "\n",
    "index_tracker = 0\n",
    "with torch.no_grad():\n",
    "    for name, param in cppn1.named_parameters():\n",
    "        # print(name)\n",
    "        if name.endswith(\"fc3.weight\"):\n",
    "            # print(param) \n",
    "            # prediction.mul_()\n",
    "            temp_tensor = prediction[index_tracker:(index_tracker + param.numel())]\n",
    "            print(param.numel())\n",
    "            temp_tensor = torch.reshape(temp_tensor, param.shape)\n",
    "            print(temp_tensor)\n",
    "            param.data.copy_(temp_tensor)\n",
    "            # print(param.numel())\n",
    "            index_tracker += param.numel()\n",
    "    \n",
    "            print(f\"{name} replacement complete\")\n",
    "\n",
    "    torch.save(cppn1.state_dict(), \"Checkpoints/CPPNsquared_output.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI4M",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
