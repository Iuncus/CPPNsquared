{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from src.CPPN1 import CPPN1\n",
    "from src.CPPN1 import CPPN1training\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"CPPNsquared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "num_steps = 50000\n",
    "batch_size = 192\n",
    "learn_rate = 0.001\n",
    "momentum = 0.9\n",
    "num_channels = 3\n",
    "image_shape = (512, 644)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPPN1(\n",
      "  (fc1): Linear(in_features=2, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fce1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cppn1 = CPPN1()\n",
    "cppn1.load_state_dict = torch.load('Checkpoints/CPPN64.pt')\n",
    "print(cppn1)\n",
    "# feature maps trasfer learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(list(cppn1.children())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weights_initialized_randomly(model):\n",
    "#     for name, param in model.named_parameters():\n",
    "#         # Check if parameter is trainable and requires gradients\n",
    "#         if param.requires_grad:\n",
    "#             # If any parameter has non-zero values, it's not randomly initialized\n",
    "#             if torch.sum(param.data) != 0:\n",
    "#                 return False\n",
    "#     return True\n",
    "\n",
    "# print(weights_initialized_randomly(cppn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fce1.weight\n",
      "fce1.bias\n",
      "fc3.weight\n",
      "fc3.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in cppn1.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map spacial coordinates\n",
    "Updated ``name.endswith`` to ``(\"fc3.weight\"):`` so I'm only training on the last layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  0.,  4.,  0.],\n",
      "        [ 3.,  1.,  4.,  0.],\n",
      "        [ 3.,  2.,  4.,  0.],\n",
      "        [ 3.,  3.,  4.,  0.],\n",
      "        [ 3.,  4.,  4.,  0.],\n",
      "        [ 3.,  5.,  4.,  0.],\n",
      "        [ 3.,  6.,  4.,  0.],\n",
      "        [ 3.,  7.,  4.,  0.],\n",
      "        [ 3.,  8.,  4.,  0.],\n",
      "        [ 3.,  9.,  4.,  0.],\n",
      "        [ 3., 10.,  4.,  0.],\n",
      "        [ 3., 11.,  4.,  0.],\n",
      "        [ 3., 12.,  4.,  0.],\n",
      "        [ 3., 13.,  4.,  0.],\n",
      "        [ 3., 14.,  4.,  0.],\n",
      "        [ 3., 15.,  4.,  0.],\n",
      "        [ 3., 16.,  4.,  0.],\n",
      "        [ 3., 17.,  4.,  0.],\n",
      "        [ 3., 18.,  4.,  0.],\n",
      "        [ 3., 19.,  4.,  0.],\n",
      "        [ 3., 20.,  4.,  0.],\n",
      "        [ 3., 21.,  4.,  0.],\n",
      "        [ 3., 22.,  4.,  0.],\n",
      "        [ 3., 23.,  4.,  0.],\n",
      "        [ 3., 24.,  4.,  0.],\n",
      "        [ 3., 25.,  4.,  0.],\n",
      "        [ 3., 26.,  4.,  0.],\n",
      "        [ 3., 27.,  4.,  0.],\n",
      "        [ 3., 28.,  4.,  0.],\n",
      "        [ 3., 29.,  4.,  0.],\n",
      "        [ 3., 30.,  4.,  0.],\n",
      "        [ 3., 31.,  4.,  0.],\n",
      "        [ 3., 32.,  4.,  0.],\n",
      "        [ 3., 33.,  4.,  0.],\n",
      "        [ 3., 34.,  4.,  0.],\n",
      "        [ 3., 35.,  4.,  0.],\n",
      "        [ 3., 36.,  4.,  0.],\n",
      "        [ 3., 37.,  4.,  0.],\n",
      "        [ 3., 38.,  4.,  0.],\n",
      "        [ 3., 39.,  4.,  0.],\n",
      "        [ 3., 40.,  4.,  0.],\n",
      "        [ 3., 41.,  4.,  0.],\n",
      "        [ 3., 42.,  4.,  0.],\n",
      "        [ 3., 43.,  4.,  0.],\n",
      "        [ 3., 44.,  4.,  0.],\n",
      "        [ 3., 45.,  4.,  0.],\n",
      "        [ 3., 46.,  4.,  0.],\n",
      "        [ 3., 47.,  4.,  0.],\n",
      "        [ 3., 48.,  4.,  0.],\n",
      "        [ 3., 49.,  4.,  0.],\n",
      "        [ 3., 50.,  4.,  0.],\n",
      "        [ 3., 51.,  4.,  0.],\n",
      "        [ 3., 52.,  4.,  0.],\n",
      "        [ 3., 53.,  4.,  0.],\n",
      "        [ 3., 54.,  4.,  0.],\n",
      "        [ 3., 55.,  4.,  0.],\n",
      "        [ 3., 56.,  4.,  0.],\n",
      "        [ 3., 57.,  4.,  0.],\n",
      "        [ 3., 58.,  4.,  0.],\n",
      "        [ 3., 59.,  4.,  0.],\n",
      "        [ 3., 60.,  4.,  0.],\n",
      "        [ 3., 61.,  4.,  0.],\n",
      "        [ 3., 62.,  4.,  0.],\n",
      "        [ 3., 63.,  4.,  0.],\n",
      "        [ 3.,  0.,  4.,  1.],\n",
      "        [ 3.,  1.,  4.,  1.],\n",
      "        [ 3.,  2.,  4.,  1.],\n",
      "        [ 3.,  3.,  4.,  1.],\n",
      "        [ 3.,  4.,  4.,  1.],\n",
      "        [ 3.,  5.,  4.,  1.],\n",
      "        [ 3.,  6.,  4.,  1.],\n",
      "        [ 3.,  7.,  4.,  1.],\n",
      "        [ 3.,  8.,  4.,  1.],\n",
      "        [ 3.,  9.,  4.,  1.],\n",
      "        [ 3., 10.,  4.,  1.],\n",
      "        [ 3., 11.,  4.,  1.],\n",
      "        [ 3., 12.,  4.,  1.],\n",
      "        [ 3., 13.,  4.,  1.],\n",
      "        [ 3., 14.,  4.,  1.],\n",
      "        [ 3., 15.,  4.,  1.],\n",
      "        [ 3., 16.,  4.,  1.],\n",
      "        [ 3., 17.,  4.,  1.],\n",
      "        [ 3., 18.,  4.,  1.],\n",
      "        [ 3., 19.,  4.,  1.],\n",
      "        [ 3., 20.,  4.,  1.],\n",
      "        [ 3., 21.,  4.,  1.],\n",
      "        [ 3., 22.,  4.,  1.],\n",
      "        [ 3., 23.,  4.,  1.],\n",
      "        [ 3., 24.,  4.,  1.],\n",
      "        [ 3., 25.,  4.,  1.],\n",
      "        [ 3., 26.,  4.,  1.],\n",
      "        [ 3., 27.,  4.,  1.],\n",
      "        [ 3., 28.,  4.,  1.],\n",
      "        [ 3., 29.,  4.,  1.],\n",
      "        [ 3., 30.,  4.,  1.],\n",
      "        [ 3., 31.,  4.,  1.],\n",
      "        [ 3., 32.,  4.,  1.],\n",
      "        [ 3., 33.,  4.,  1.],\n",
      "        [ 3., 34.,  4.,  1.],\n",
      "        [ 3., 35.,  4.,  1.],\n",
      "        [ 3., 36.,  4.,  1.],\n",
      "        [ 3., 37.,  4.,  1.],\n",
      "        [ 3., 38.,  4.,  1.],\n",
      "        [ 3., 39.,  4.,  1.],\n",
      "        [ 3., 40.,  4.,  1.],\n",
      "        [ 3., 41.,  4.,  1.],\n",
      "        [ 3., 42.,  4.,  1.],\n",
      "        [ 3., 43.,  4.,  1.],\n",
      "        [ 3., 44.,  4.,  1.],\n",
      "        [ 3., 45.,  4.,  1.],\n",
      "        [ 3., 46.,  4.,  1.],\n",
      "        [ 3., 47.,  4.,  1.],\n",
      "        [ 3., 48.,  4.,  1.],\n",
      "        [ 3., 49.,  4.,  1.],\n",
      "        [ 3., 50.,  4.,  1.],\n",
      "        [ 3., 51.,  4.,  1.],\n",
      "        [ 3., 52.,  4.,  1.],\n",
      "        [ 3., 53.,  4.,  1.],\n",
      "        [ 3., 54.,  4.,  1.],\n",
      "        [ 3., 55.,  4.,  1.],\n",
      "        [ 3., 56.,  4.,  1.],\n",
      "        [ 3., 57.,  4.,  1.],\n",
      "        [ 3., 58.,  4.,  1.],\n",
      "        [ 3., 59.,  4.,  1.],\n",
      "        [ 3., 60.,  4.,  1.],\n",
      "        [ 3., 61.,  4.,  1.],\n",
      "        [ 3., 62.,  4.,  1.],\n",
      "        [ 3., 63.,  4.,  1.],\n",
      "        [ 3.,  0.,  4.,  2.],\n",
      "        [ 3.,  1.,  4.,  2.],\n",
      "        [ 3.,  2.,  4.,  2.],\n",
      "        [ 3.,  3.,  4.,  2.],\n",
      "        [ 3.,  4.,  4.,  2.],\n",
      "        [ 3.,  5.,  4.,  2.],\n",
      "        [ 3.,  6.,  4.,  2.],\n",
      "        [ 3.,  7.,  4.,  2.],\n",
      "        [ 3.,  8.,  4.,  2.],\n",
      "        [ 3.,  9.,  4.,  2.],\n",
      "        [ 3., 10.,  4.,  2.],\n",
      "        [ 3., 11.,  4.,  2.],\n",
      "        [ 3., 12.,  4.,  2.],\n",
      "        [ 3., 13.,  4.,  2.],\n",
      "        [ 3., 14.,  4.,  2.],\n",
      "        [ 3., 15.,  4.,  2.],\n",
      "        [ 3., 16.,  4.,  2.],\n",
      "        [ 3., 17.,  4.,  2.],\n",
      "        [ 3., 18.,  4.,  2.],\n",
      "        [ 3., 19.,  4.,  2.],\n",
      "        [ 3., 20.,  4.,  2.],\n",
      "        [ 3., 21.,  4.,  2.],\n",
      "        [ 3., 22.,  4.,  2.],\n",
      "        [ 3., 23.,  4.,  2.],\n",
      "        [ 3., 24.,  4.,  2.],\n",
      "        [ 3., 25.,  4.,  2.],\n",
      "        [ 3., 26.,  4.,  2.],\n",
      "        [ 3., 27.,  4.,  2.],\n",
      "        [ 3., 28.,  4.,  2.],\n",
      "        [ 3., 29.,  4.,  2.],\n",
      "        [ 3., 30.,  4.,  2.],\n",
      "        [ 3., 31.,  4.,  2.],\n",
      "        [ 3., 32.,  4.,  2.],\n",
      "        [ 3., 33.,  4.,  2.],\n",
      "        [ 3., 34.,  4.,  2.],\n",
      "        [ 3., 35.,  4.,  2.],\n",
      "        [ 3., 36.,  4.,  2.],\n",
      "        [ 3., 37.,  4.,  2.],\n",
      "        [ 3., 38.,  4.,  2.],\n",
      "        [ 3., 39.,  4.,  2.],\n",
      "        [ 3., 40.,  4.,  2.],\n",
      "        [ 3., 41.,  4.,  2.],\n",
      "        [ 3., 42.,  4.,  2.],\n",
      "        [ 3., 43.,  4.,  2.],\n",
      "        [ 3., 44.,  4.,  2.],\n",
      "        [ 3., 45.,  4.,  2.],\n",
      "        [ 3., 46.,  4.,  2.],\n",
      "        [ 3., 47.,  4.,  2.],\n",
      "        [ 3., 48.,  4.,  2.],\n",
      "        [ 3., 49.,  4.,  2.],\n",
      "        [ 3., 50.,  4.,  2.],\n",
      "        [ 3., 51.,  4.,  2.],\n",
      "        [ 3., 52.,  4.,  2.],\n",
      "        [ 3., 53.,  4.,  2.],\n",
      "        [ 3., 54.,  4.,  2.],\n",
      "        [ 3., 55.,  4.,  2.],\n",
      "        [ 3., 56.,  4.,  2.],\n",
      "        [ 3., 57.,  4.,  2.],\n",
      "        [ 3., 58.,  4.,  2.],\n",
      "        [ 3., 59.,  4.,  2.],\n",
      "        [ 3., 60.,  4.,  2.],\n",
      "        [ 3., 61.,  4.,  2.],\n",
      "        [ 3., 62.,  4.,  2.],\n",
      "        [ 3., 63.,  4.,  2.]], device='cuda:0')\n",
      "[[0.5, -1.0, 1.0, -1.0], [0.5, -0.9682539701461792, 1.0, -1.0], [0.5, -0.9365079402923584, 1.0, -1.0], [0.5, -0.9047619104385376, 1.0, -1.0], [0.5, -0.8730158805847168, 1.0, -1.0], [0.5, -0.841269850730896, 1.0, -1.0], [0.5, -0.8095238208770752, 1.0, -1.0], [0.5, -0.7777777910232544, 1.0, -1.0], [0.5, -0.7460317611694336, 1.0, -1.0], [0.5, -0.7142857313156128, 1.0, -1.0], [0.5, -0.682539701461792, 1.0, -1.0], [0.5, -0.6507936716079712, 1.0, -1.0], [0.5, -0.6190476417541504, 1.0, -1.0], [0.5, -0.5873016119003296, 1.0, -1.0], [0.5, -0.5555555820465088, 1.0, -1.0], [0.5, -0.523809552192688, 1.0, -1.0], [0.5, -0.4920634627342224, 1.0, -1.0], [0.5, -0.4603174328804016, 1.0, -1.0], [0.5, -0.4285714030265808, 1.0, -1.0], [0.5, -0.39682537317276, 1.0, -1.0], [0.5, -0.3650793433189392, 1.0, -1.0], [0.5, -0.3333333134651184, 1.0, -1.0], [0.5, -0.3015872836112976, 1.0, -1.0], [0.5, -0.2698412537574768, 1.0, -1.0], [0.5, -0.238095223903656, 1.0, -1.0], [0.5, -0.2063491940498352, 1.0, -1.0], [0.5, -0.1746031641960144, 1.0, -1.0], [0.5, -0.1428571343421936, 1.0, -1.0], [0.5, -0.1111111044883728, 1.0, -1.0], [0.5, -0.079365074634552, 1.0, -1.0], [0.5, -0.0476190447807312, 1.0, -1.0], [0.5, -0.0158730149269104, 1.0, -1.0], [0.5, 0.015873074531555176, 1.0, -1.0], [0.5, 0.04761910438537598, 1.0, -1.0], [0.5, 0.07936513423919678, 1.0, -1.0], [0.5, 0.11111116409301758, 1.0, -1.0], [0.5, 0.14285719394683838, 1.0, -1.0], [0.5, 0.17460322380065918, 1.0, -1.0], [0.5, 0.20634925365447998, 1.0, -1.0], [0.5, 0.23809528350830078, 1.0, -1.0], [0.5, 0.2698413133621216, 1.0, -1.0], [0.5, 0.3015873432159424, 1.0, -1.0], [0.5, 0.3333333730697632, 1.0, -1.0], [0.5, 0.365079402923584, 1.0, -1.0], [0.5, 0.3968254327774048, 1.0, -1.0], [0.5, 0.4285714626312256, 1.0, -1.0], [0.5, 0.4603174924850464, 1.0, -1.0], [0.5, 0.4920635223388672, 1.0, -1.0], [0.5, 0.523809552192688, 1.0, -1.0], [0.5, 0.5555555820465088, 1.0, -1.0], [0.5, 0.5873016119003296, 1.0, -1.0], [0.5, 0.6190476417541504, 1.0, -1.0], [0.5, 0.6507936716079712, 1.0, -1.0], [0.5, 0.682539701461792, 1.0, -1.0], [0.5, 0.7142857313156128, 1.0, -1.0], [0.5, 0.7460317611694336, 1.0, -1.0], [0.5, 0.7777777910232544, 1.0, -1.0], [0.5, 0.8095238208770752, 1.0, -1.0], [0.5, 0.841269850730896, 1.0, -1.0], [0.5, 0.8730158805847168, 1.0, -1.0], [0.5, 0.9047619104385376, 1.0, -1.0], [0.5, 0.9365079402923584, 1.0, -1.0], [0.5, 0.9682539701461792, 1.0, -1.0], [0.5, 1.0, 1.0, -1.0], [0.5, -1.0, 1.0, 0.0], [0.5, -0.9682539701461792, 1.0, 0.0], [0.5, -0.9365079402923584, 1.0, 0.0], [0.5, -0.9047619104385376, 1.0, 0.0], [0.5, -0.8730158805847168, 1.0, 0.0], [0.5, -0.841269850730896, 1.0, 0.0], [0.5, -0.8095238208770752, 1.0, 0.0], [0.5, -0.7777777910232544, 1.0, 0.0], [0.5, -0.7460317611694336, 1.0, 0.0], [0.5, -0.7142857313156128, 1.0, 0.0], [0.5, -0.682539701461792, 1.0, 0.0], [0.5, -0.6507936716079712, 1.0, 0.0], [0.5, -0.6190476417541504, 1.0, 0.0], [0.5, -0.5873016119003296, 1.0, 0.0], [0.5, -0.5555555820465088, 1.0, 0.0], [0.5, -0.523809552192688, 1.0, 0.0], [0.5, -0.4920634627342224, 1.0, 0.0], [0.5, -0.4603174328804016, 1.0, 0.0], [0.5, -0.4285714030265808, 1.0, 0.0], [0.5, -0.39682537317276, 1.0, 0.0], [0.5, -0.3650793433189392, 1.0, 0.0], [0.5, -0.3333333134651184, 1.0, 0.0], [0.5, -0.3015872836112976, 1.0, 0.0], [0.5, -0.2698412537574768, 1.0, 0.0], [0.5, -0.238095223903656, 1.0, 0.0], [0.5, -0.2063491940498352, 1.0, 0.0], [0.5, -0.1746031641960144, 1.0, 0.0], [0.5, -0.1428571343421936, 1.0, 0.0], [0.5, -0.1111111044883728, 1.0, 0.0], [0.5, -0.079365074634552, 1.0, 0.0], [0.5, -0.0476190447807312, 1.0, 0.0], [0.5, -0.0158730149269104, 1.0, 0.0], [0.5, 0.015873074531555176, 1.0, 0.0], [0.5, 0.04761910438537598, 1.0, 0.0], [0.5, 0.07936513423919678, 1.0, 0.0], [0.5, 0.11111116409301758, 1.0, 0.0], [0.5, 0.14285719394683838, 1.0, 0.0], [0.5, 0.17460322380065918, 1.0, 0.0], [0.5, 0.20634925365447998, 1.0, 0.0], [0.5, 0.23809528350830078, 1.0, 0.0], [0.5, 0.2698413133621216, 1.0, 0.0], [0.5, 0.3015873432159424, 1.0, 0.0], [0.5, 0.3333333730697632, 1.0, 0.0], [0.5, 0.365079402923584, 1.0, 0.0], [0.5, 0.3968254327774048, 1.0, 0.0], [0.5, 0.4285714626312256, 1.0, 0.0], [0.5, 0.4603174924850464, 1.0, 0.0], [0.5, 0.4920635223388672, 1.0, 0.0], [0.5, 0.523809552192688, 1.0, 0.0], [0.5, 0.5555555820465088, 1.0, 0.0], [0.5, 0.5873016119003296, 1.0, 0.0], [0.5, 0.6190476417541504, 1.0, 0.0], [0.5, 0.6507936716079712, 1.0, 0.0], [0.5, 0.682539701461792, 1.0, 0.0], [0.5, 0.7142857313156128, 1.0, 0.0], [0.5, 0.7460317611694336, 1.0, 0.0], [0.5, 0.7777777910232544, 1.0, 0.0], [0.5, 0.8095238208770752, 1.0, 0.0], [0.5, 0.841269850730896, 1.0, 0.0], [0.5, 0.8730158805847168, 1.0, 0.0], [0.5, 0.9047619104385376, 1.0, 0.0], [0.5, 0.9365079402923584, 1.0, 0.0], [0.5, 0.9682539701461792, 1.0, 0.0], [0.5, 1.0, 1.0, 0.0], [0.5, -1.0, 1.0, 1.0], [0.5, -0.9682539701461792, 1.0, 1.0], [0.5, -0.9365079402923584, 1.0, 1.0], [0.5, -0.9047619104385376, 1.0, 1.0], [0.5, -0.8730158805847168, 1.0, 1.0], [0.5, -0.841269850730896, 1.0, 1.0], [0.5, -0.8095238208770752, 1.0, 1.0], [0.5, -0.7777777910232544, 1.0, 1.0], [0.5, -0.7460317611694336, 1.0, 1.0], [0.5, -0.7142857313156128, 1.0, 1.0], [0.5, -0.682539701461792, 1.0, 1.0], [0.5, -0.6507936716079712, 1.0, 1.0], [0.5, -0.6190476417541504, 1.0, 1.0], [0.5, -0.5873016119003296, 1.0, 1.0], [0.5, -0.5555555820465088, 1.0, 1.0], [0.5, -0.523809552192688, 1.0, 1.0], [0.5, -0.4920634627342224, 1.0, 1.0], [0.5, -0.4603174328804016, 1.0, 1.0], [0.5, -0.4285714030265808, 1.0, 1.0], [0.5, -0.39682537317276, 1.0, 1.0], [0.5, -0.3650793433189392, 1.0, 1.0], [0.5, -0.3333333134651184, 1.0, 1.0], [0.5, -0.3015872836112976, 1.0, 1.0], [0.5, -0.2698412537574768, 1.0, 1.0], [0.5, -0.238095223903656, 1.0, 1.0], [0.5, -0.2063491940498352, 1.0, 1.0], [0.5, -0.1746031641960144, 1.0, 1.0], [0.5, -0.1428571343421936, 1.0, 1.0], [0.5, -0.1111111044883728, 1.0, 1.0], [0.5, -0.079365074634552, 1.0, 1.0], [0.5, -0.0476190447807312, 1.0, 1.0], [0.5, -0.0158730149269104, 1.0, 1.0], [0.5, 0.015873074531555176, 1.0, 1.0], [0.5, 0.04761910438537598, 1.0, 1.0], [0.5, 0.07936513423919678, 1.0, 1.0], [0.5, 0.11111116409301758, 1.0, 1.0], [0.5, 0.14285719394683838, 1.0, 1.0], [0.5, 0.17460322380065918, 1.0, 1.0], [0.5, 0.20634925365447998, 1.0, 1.0], [0.5, 0.23809528350830078, 1.0, 1.0], [0.5, 0.2698413133621216, 1.0, 1.0], [0.5, 0.3015873432159424, 1.0, 1.0], [0.5, 0.3333333730697632, 1.0, 1.0], [0.5, 0.365079402923584, 1.0, 1.0], [0.5, 0.3968254327774048, 1.0, 1.0], [0.5, 0.4285714626312256, 1.0, 1.0], [0.5, 0.4603174924850464, 1.0, 1.0], [0.5, 0.4920635223388672, 1.0, 1.0], [0.5, 0.523809552192688, 1.0, 1.0], [0.5, 0.5555555820465088, 1.0, 1.0], [0.5, 0.5873016119003296, 1.0, 1.0], [0.5, 0.6190476417541504, 1.0, 1.0], [0.5, 0.6507936716079712, 1.0, 1.0], [0.5, 0.682539701461792, 1.0, 1.0], [0.5, 0.7142857313156128, 1.0, 1.0], [0.5, 0.7460317611694336, 1.0, 1.0], [0.5, 0.7777777910232544, 1.0, 1.0], [0.5, 0.8095238208770752, 1.0, 1.0], [0.5, 0.841269850730896, 1.0, 1.0], [0.5, 0.8730158805847168, 1.0, 1.0], [0.5, 0.9047619104385376, 1.0, 1.0], [0.5, 0.9365079402923584, 1.0, 1.0], [0.5, 0.9682539701461792, 1.0, 1.0], [0.5, 1.0, 1.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "parameter_info = []\n",
    "fc1 = []\n",
    "full_coords = []\n",
    "full_weights = []\n",
    "layer_count = len(list(cppn1.children()))\n",
    "\n",
    "\n",
    "def normalize(tensor, axis):\n",
    "    if axis % 2 == 0:\n",
    "        max_vals = layer_count\n",
    "        min_vals = 0\n",
    "    else:\n",
    "        max_vals, _ = torch.max(tensor, dim=0)\n",
    "        min_vals, _ = torch.min(tensor, dim=0)\n",
    "\n",
    "    normalized_tensor = 2 * (tensor - min_vals) / (max_vals - min_vals) - 1\n",
    "    return normalized_tensor\n",
    "\n",
    "def spatial_coords(array, layer):\n",
    "\n",
    "    coords = []\n",
    "    row1 = []\n",
    "    row2 = []\n",
    "    for i in range(array.shape[0]):\n",
    "        row2.append([layer+1, i])\n",
    "    for i in range(array.shape[1]):\n",
    "        row1.append([layer, i])\n",
    "            \n",
    "    array = array.flatten(\"C\").tolist()\n",
    "    # print(array)\n",
    "    for i in row2:\n",
    "        for j in row1:\n",
    "            temp = []\n",
    "            temp.extend(j)\n",
    "            temp.extend(i)\n",
    "            coords.append((temp))\n",
    "    # coords_array = np.array(coords)\n",
    "    # coords_array.astype(int)\n",
    "    # output = np.column_stack((coords_array, array))\n",
    "\n",
    "    # print(len(output))\n",
    "    return coords, array\n",
    "            \n",
    "    # array.flatten()\n",
    "    # return np.stack((array, coords))\n",
    "\n",
    "index = 0\n",
    "for name, param in cppn1.named_parameters():\n",
    "    \n",
    "    # print(name)\n",
    "    if name.endswith(\"fc3.weight\"):\n",
    "        \n",
    "        # print(index)\n",
    "        # print(param)\n",
    "        temp_layer = param.detach().numpy() # need to learn more about gradients and why they are required\n",
    "        # print(temp_layer)\n",
    "\n",
    "        temp_coords, temp_weights = spatial_coords(temp_layer, 3)\n",
    "        temp_coords = torch.tensor(temp_coords, device=device, dtype=torch.float32)\n",
    "        normal = temp_coords\n",
    "        print(temp_coords)\n",
    "        for i in range(4):\n",
    "            # print(i)\n",
    "            normal[:,i] = normalize(temp_coords[:, i], i)\n",
    "            # normal = torch.nan_to_num(normal, nan = 0)\n",
    "        if index == 3:\n",
    "            # print(temp_coords)\n",
    "            print(normal)\n",
    "            # print(normal)\n",
    "        full_coords.extend(normal.tolist())\n",
    "        full_weights.extend(temp_weights)\n",
    "\n",
    "        index += 1\n",
    "        # print(fc1.shape[0])\n",
    "\n",
    "print(full_coords)\n",
    "\n",
    "# print(full_weights)\n",
    "    \n",
    "# layer1_coords, layer1_weights = spatial_coords(fce1, 2)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize =(12,8))\n",
    "# ax.scatter(range(len(full_weights)), full_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up CPPN_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPPN_squared(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "      super(CPPN_squared, self).__init__()\n",
    "\n",
    "      self.fc1 = nn.Linear(4, 16)\n",
    "\n",
    "      self.fc2 = nn.Linear(16, 64)\n",
    "      self.fce1 = nn.Linear(64, 64)\n",
    "      self.fce2 = nn.Linear(64, 16)\n",
    "\n",
    "      self.fc3 = nn.Linear(16, 1)     \n",
    "\n",
    "    #   self.init_weights()\n",
    "      \n",
    "    # def init_weights(self):\n",
    "    #   for m in self.modules():\n",
    "    #       if isinstance(m, nn.Linear):\n",
    "    #           # Initialize weights using Xavier initialization\n",
    "    #           init.xavier_normal_(m.weight)\n",
    "    #           # Initialize biases to zeros\n",
    "    #           init.constant_(m.bias, 0)\n",
    "    \n",
    "    # defines forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        # x = torch.sin(x)\n",
    "        x = F.relu(x)\n",
    "        # x = F.tanh(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        # x = torch.sin(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fce1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fce2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        # x = F.sigmoid(x)\n",
    "\n",
    "        # returns the output of layer 3 after activation\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPPN_squared = CPPN_squared()\n",
    "# wandb.watch(CPPN_squared)\n",
    "CPPN_squared.to(device)\n",
    "CPPN_squared.requires_grad_()\n",
    "\n",
    "# optimiser = torch.optim.SGD(cppn.parameters(), lr=learn_rate, momentum=momentum)\n",
    "optimiser = torch.optim.Adam(CPPN_squared.parameters(), lr=learn_rate)\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "# criterion = nn.L1Loss(reduction = \"mean\")\n",
    "# criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_minus1_to_1(tensor):\n",
    "    min_vals, _ = torch.min(tensor, dim=0)\n",
    "    max_vals, _ = torch.max(tensor, dim=0)\n",
    "    normalized_tensor = 2 * (tensor - min_vals) / (max_vals - min_vals) - 1\n",
    "    return normalized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0623, -0.0678,  0.0110, -0.0177, -0.1250, -0.0914,  0.1056, -0.0044,\n",
      "        -0.0021, -0.0341, -0.1097, -0.0950,  0.0959,  0.1218, -0.0053, -0.1167,\n",
      "         0.1124,  0.1159, -0.0580, -0.0861, -0.0163,  0.0387,  0.0165, -0.0848,\n",
      "        -0.0187,  0.1052, -0.0641,  0.0196, -0.0411,  0.1119,  0.1048,  0.0823,\n",
      "        -0.0950, -0.1157,  0.0773,  0.0349, -0.0173, -0.0375,  0.0826, -0.0864,\n",
      "         0.0153, -0.1180, -0.0829,  0.0738,  0.0236, -0.0188, -0.0585,  0.0420,\n",
      "        -0.0530, -0.0429, -0.0131, -0.0898,  0.0187,  0.0471,  0.0450, -0.0987,\n",
      "        -0.0834,  0.0812,  0.0760, -0.0309, -0.0920, -0.0136,  0.1205,  0.0408,\n",
      "         0.0045, -0.0264,  0.0231, -0.0229, -0.0762, -0.0517, -0.0725, -0.0890,\n",
      "         0.0026, -0.0515, -0.0799, -0.0455,  0.0021,  0.0041, -0.0099,  0.0757,\n",
      "         0.1246,  0.0850,  0.0086,  0.1192, -0.0191,  0.0639, -0.0020,  0.0027,\n",
      "        -0.1027, -0.0293,  0.1110,  0.1010,  0.0722, -0.0192,  0.1085, -0.0905,\n",
      "         0.0475,  0.0588,  0.1073,  0.1100, -0.0749, -0.0729, -0.0499, -0.1052,\n",
      "        -0.0748, -0.1065,  0.0008, -0.0197, -0.0659, -0.0829,  0.0206, -0.1025,\n",
      "        -0.0814,  0.0502, -0.0794, -0.0976,  0.0399, -0.0635,  0.0331, -0.0483,\n",
      "        -0.0820, -0.0401, -0.0195, -0.1247,  0.0981, -0.0998, -0.1060, -0.0965,\n",
      "        -0.1025, -0.1080,  0.0131,  0.0292, -0.0908, -0.0088,  0.0862,  0.0086,\n",
      "         0.1123,  0.0379, -0.0126, -0.0913, -0.0584, -0.0744,  0.0257,  0.0745,\n",
      "         0.0525,  0.0531, -0.0916,  0.0672,  0.0351, -0.1146,  0.0973,  0.0727,\n",
      "        -0.0617, -0.0391, -0.0830, -0.0766,  0.0969,  0.0286,  0.0650,  0.0417,\n",
      "        -0.0369, -0.0687, -0.0221, -0.0143,  0.0300,  0.1022, -0.0379, -0.0384,\n",
      "        -0.0862,  0.1030, -0.0580, -0.0299, -0.0983,  0.0288,  0.1173, -0.0582,\n",
      "         0.0077, -0.0869, -0.1219, -0.0673, -0.0793, -0.1128, -0.0948,  0.0055,\n",
      "         0.0183, -0.0922,  0.0901,  0.1159, -0.0499,  0.0735, -0.0344,  0.0070],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "normalized_coords_matrix = torch.tensor(full_coords, device=device, dtype=torch.float32)\n",
    "\n",
    "# Normalize the coordinates matrix along each column\n",
    "# normalized_coords_matrix = normalize_minus1_to_1(all_xy_coordinates)\n",
    "# print(normalized_coords_matrix)\n",
    "\n",
    "all_pixel_values = torch.tensor(full_weights, device=device, dtype=torch.float32)\n",
    "# all_pixel_values = (all_pixel_values + 1)/2\n",
    "# all_pixel_values = torch.unsqueeze(all_pixel_values, 0)\n",
    "print(all_pixel_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training and validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train, test = train_test_split(normalized_coords_matrix, test_size= 0.2, random_state=42)\n",
    "train_coords, val_coords, train_pixel_values, val_pixel_values = train_test_split(normalized_coords_matrix, all_pixel_values, test_size=0.1, random_state=42)\n",
    "# import math\n",
    "batch_size = int(batch_size * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5000, -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.9683,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.9365,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.9048,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.8730,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.8413,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.8095,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.7778,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.7460,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.7143,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.6825,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.6508,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.6190,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.5873,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.5556,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.5238,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.4921,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.4603,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.4286,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.3968,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.3651,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.3333,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.3016,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.2698,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.2381,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.2063,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.1746,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.1429,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.1111,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.0794,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.0476,  1.0000, -1.0000],\n",
      "        [ 0.5000, -0.0159,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.0159,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.0476,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.0794,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.1111,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.1429,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.1746,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.2063,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.2381,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.2698,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.3016,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.3333,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.3651,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.3968,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.4286,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.4603,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.4921,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.5238,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.5556,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.5873,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.6190,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.6508,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.6825,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.7143,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.7460,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.7778,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.8095,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.8413,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.8730,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.9048,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.9365,  1.0000, -1.0000],\n",
      "        [ 0.5000,  0.9683,  1.0000, -1.0000],\n",
      "        [ 0.5000,  1.0000,  1.0000, -1.0000],\n",
      "        [ 0.5000, -1.0000,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.9683,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.9365,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.9048,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.8730,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.8413,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.8095,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.7778,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.7460,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.7143,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.6825,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.6508,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.6190,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.5873,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.5556,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.5238,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.4921,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.4603,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.4286,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.3968,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.3651,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.3333,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.3016,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.2698,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.2381,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.2063,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.1746,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.1429,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.1111,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.0794,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.0476,  1.0000,  0.0000],\n",
      "        [ 0.5000, -0.0159,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.0159,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.0476,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.0794,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.1111,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.1429,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.1746,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.2063,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.2381,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.2698,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.3016,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.3333,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.3651,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.3968,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.4286,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.4603,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.4921,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.5238,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.5556,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.5873,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.6190,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.6508,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.6825,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.7143,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.7460,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.7778,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.8095,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.8413,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.8730,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.9048,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.9365,  1.0000,  0.0000],\n",
      "        [ 0.5000,  0.9683,  1.0000,  0.0000],\n",
      "        [ 0.5000,  1.0000,  1.0000,  0.0000],\n",
      "        [ 0.5000, -1.0000,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.9683,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.9365,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.9048,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.8730,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.8413,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.8095,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.7778,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.7460,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.7143,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.6825,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.6508,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.6190,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.5873,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.5556,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.5238,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.4921,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.4603,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.4286,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.3968,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.3651,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.3333,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.3016,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.2698,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.2381,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.2063,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.1746,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.1429,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.1111,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.0794,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.0476,  1.0000,  1.0000],\n",
      "        [ 0.5000, -0.0159,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0159,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0476,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0794,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.1111,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.1429,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.1746,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.2063,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.2381,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.2698,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.3016,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.3333,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.3651,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.3968,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.4286,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.4603,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.4921,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.5238,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.5556,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.5873,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.6190,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.6508,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.6825,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.7143,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.7460,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.7778,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.8095,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.8413,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.8730,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.9048,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.9365,  1.0000,  1.0000],\n",
      "        [ 0.5000,  0.9683,  1.0000,  1.0000],\n",
      "        [ 0.5000,  1.0000,  1.0000,  1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(normalized_coords_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 0.000\n",
      "Validation - Step 0, loss 0.070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10000, loss 0.004\n",
      "Validation - Step 10000, loss 0.008\n",
      "step 20000, loss 0.003\n",
      "Validation - Step 20000, loss 0.012\n",
      "step 30000, loss 0.002\n",
      "Validation - Step 30000, loss 0.010\n",
      "step 40000, loss 0.002\n",
      "Validation - Step 40000, loss 0.011\n"
     ]
    }
   ],
   "source": [
    "num_coords = normalized_coords_matrix.shape[0]\n",
    "coord_indexes = list(range(0, num_coords))\n",
    "losses = []\n",
    "img_list = []\n",
    "running_loss = 0.0\n",
    "best_loss = 10000000\n",
    "best_val_loss = 10000000\n",
    "display_num = 10000\n",
    "# training loop\n",
    "for i in range(num_steps):\n",
    "    optimiser.zero_grad()\n",
    "    CPPN_squared.zero_grad()\n",
    "\n",
    "    # Sample a random batch of indexes from the list coord_indexes\n",
    "    training_batch_indexes = torch.tensor(np.array(random.sample(range(0, train_coords.shape[0]), batch_size)))\n",
    "    \n",
    "    # Get batch of respective xy_coordiantes\n",
    "    training_coords_batch = normalized_coords_matrix[training_batch_indexes]\n",
    "    \n",
    "    # And respective pixel values \n",
    "    pixel_values_batch = train_pixel_values[training_batch_indexes]\n",
    "    pixel_values_batch = pixel_values_batch.unsqueeze(1)\n",
    "    \n",
    "    # Process data with model\n",
    "    approx_pixel_values = CPPN_squared(training_coords_batch)\n",
    "    \n",
    "    # Calculate and track loss function\n",
    "    loss = criterion(approx_pixel_values, pixel_values_batch)\n",
    "    running_loss += loss.item()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if i % display_num == 0:\n",
    "        if running_loss < best_loss:\n",
    "            best_loss = running_loss\n",
    "            torch.save(CPPN_squared.state_dict(), 'Checkpoints/CPPN2model.pt')\n",
    "        print(f'step {i}, loss {running_loss/display_num:.3f}')\n",
    "        # wandb.log({\"loss\": loss.item()})\n",
    "        running_loss = 0.0\n",
    "\n",
    "        #validation loop\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            val_output = CPPN_squared(val_coords)\n",
    "            val_loss += criterion(val_output,val_pixel_values.unsqueeze(1)).item()\n",
    "\n",
    "                \n",
    "            print(f'Validation - Step {i}, loss {val_loss:.3f}')\n",
    "            # wandb.log({\"val_loss\": val_loss})\n",
    "\n",
    "            \n",
    "    #Update model\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    # wandb.log({\"final_weights\": CPPN_squared.state_dict()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([192])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    torch.set_printoptions(profile=\"full\")\n",
    "    prediction = CPPN_squared(normalized_coords_matrix)\n",
    "    prediction = prediction.flatten(0)\n",
    "    # prediction = prediction * 2 - 1\n",
    "    print(prediction.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0623, -0.0678,  0.0110, -0.0177, -0.1250, -0.0914,  0.1056, -0.0044,\n",
      "        -0.0021, -0.0341, -0.1097, -0.0950,  0.0959,  0.1218, -0.0053, -0.1167,\n",
      "         0.1124,  0.1159, -0.0580, -0.0861, -0.0163,  0.0387,  0.0165, -0.0848,\n",
      "        -0.0187,  0.1052, -0.0641,  0.0196, -0.0411,  0.1119,  0.1048,  0.0823,\n",
      "        -0.0950, -0.1157,  0.0773,  0.0349, -0.0173, -0.0375,  0.0826, -0.0864,\n",
      "         0.0153, -0.1180, -0.0829,  0.0738,  0.0236, -0.0188, -0.0585,  0.0420,\n",
      "        -0.0530, -0.0429, -0.0131, -0.0898,  0.0187,  0.0471,  0.0450, -0.0987,\n",
      "        -0.0834,  0.0812,  0.0760, -0.0309, -0.0920, -0.0136,  0.1205,  0.0408,\n",
      "         0.0045, -0.0264,  0.0231, -0.0229, -0.0762, -0.0517, -0.0725, -0.0890,\n",
      "         0.0026, -0.0515, -0.0799, -0.0455,  0.0021,  0.0041, -0.0099,  0.0757,\n",
      "         0.1246,  0.0850,  0.0086,  0.1192, -0.0191,  0.0639, -0.0020,  0.0027,\n",
      "        -0.1027, -0.0293,  0.1110,  0.1010,  0.0722, -0.0192,  0.1085, -0.0905,\n",
      "         0.0475,  0.0588,  0.1073,  0.1100, -0.0749, -0.0729, -0.0499, -0.1052,\n",
      "        -0.0748, -0.1065,  0.0008, -0.0197, -0.0659, -0.0829,  0.0206, -0.1025,\n",
      "        -0.0814,  0.0502, -0.0794, -0.0976,  0.0399, -0.0635,  0.0331, -0.0483,\n",
      "        -0.0820, -0.0401, -0.0195, -0.1247,  0.0981, -0.0998, -0.1060, -0.0965,\n",
      "        -0.1025, -0.1080,  0.0131,  0.0292, -0.0908, -0.0088,  0.0862,  0.0086,\n",
      "         0.1123,  0.0379, -0.0126, -0.0913, -0.0584, -0.0744,  0.0257,  0.0745,\n",
      "         0.0525,  0.0531, -0.0916,  0.0672,  0.0351, -0.1146,  0.0973,  0.0727,\n",
      "        -0.0617, -0.0391, -0.0830, -0.0766,  0.0969,  0.0286,  0.0650,  0.0417,\n",
      "        -0.0369, -0.0687, -0.0221, -0.0143,  0.0300,  0.1022, -0.0379, -0.0384,\n",
      "        -0.0862,  0.1030, -0.0580, -0.0299, -0.0983,  0.0288,  0.1173, -0.0582,\n",
      "         0.0077, -0.0869, -0.1219, -0.0673, -0.0793, -0.1128, -0.0948,  0.0055,\n",
      "         0.0183, -0.0922,  0.0901,  0.1159, -0.0499,  0.0735, -0.0344,  0.0070],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(all_pixel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'target')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharey=True, figsize = (15, 6))\n",
    "# ax[0].set_ylim([0.1, 0.9])\n",
    "x_values = np.arange(len(prediction.cpu().numpy()))\n",
    "\n",
    "ax[0].scatter(x_values, prediction.cpu().numpy(), marker='o', s=2)\n",
    "ax[0].set_title(\"prediction\")\n",
    "ax[1].scatter(x_values, all_pixel_values.cpu().numpy(), marker='o', s=2)\n",
    "ax[1].set_title(\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly updated ``name.endswith`` to ``(\"fc3.weight\"):`` so I'm only replacing the last layer with new weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "tensor([[-1.8251e-02, -7.0681e-02,  4.3053e-02,  1.1698e-01, -7.6289e-03,\n",
      "         -3.0409e-02, -3.1709e-02, -3.3324e-02, -3.8615e-02, -4.3906e-02,\n",
      "         -4.9609e-02, -5.7062e-02, -6.4516e-02,  1.2194e-01, -4.6973e-02,\n",
      "         -7.3779e-02, -1.8712e-02,  3.6356e-02,  9.3034e-02,  2.5545e-02,\n",
      "         -4.1552e-02, -1.2235e-02,  1.7083e-02, -1.4030e-02, -4.8511e-02,\n",
      "         -7.9846e-02, -7.1174e-02, -6.2503e-02, -5.3587e-02, -7.9026e-02,\n",
      "          7.3549e-02,  4.0087e-02,  6.5511e-03, -2.1971e-02,  6.1433e-03,\n",
      "          3.4258e-02,  6.2237e-02,  2.5138e-02, -1.2074e-02, -6.4507e-02,\n",
      "          4.8550e-02,  8.6945e-02,  4.7187e-02,  7.4287e-03, -3.2329e-02,\n",
      "         -6.6476e-02, -4.1943e-02, -1.7368e-02,  5.0327e-03, -4.7942e-02,\n",
      "         -6.6866e-02, -1.5808e-02, -7.5317e-02, -5.5459e-02, -3.5555e-02,\n",
      "         -7.0782e-03,  1.9308e-02, -6.0882e-02, -9.4880e-02, -8.3127e-02,\n",
      "         -6.4380e-02, -5.0456e-02,  1.0806e-01,  2.2897e-02],\n",
      "        [-6.4552e-02, -1.1319e-01, -8.7097e-02,  1.0155e-01, -7.9049e-03,\n",
      "         -1.3223e-02,  4.5885e-02, -9.8776e-02,  9.2155e-02,  5.7532e-02,\n",
      "          2.2581e-02, -1.2371e-02, -5.5378e-02, -9.8556e-02, -6.2216e-02,\n",
      "          1.1262e-01,  5.7441e-02,  2.2589e-03, -5.2923e-02, -2.9552e-02,\n",
      "         -6.0692e-03,  1.7414e-02,  4.0897e-02,  6.4081e-02, -4.0592e-02,\n",
      "         -8.0875e-03,  2.4417e-02,  5.2859e-02,  2.6543e-02,  2.2614e-04,\n",
      "         -2.6091e-02, -5.2407e-02, -5.1713e-02, -2.8920e-02, -6.1280e-03,\n",
      "          1.6664e-02,  3.9456e-02,  6.2248e-02,  8.5040e-02,  6.8092e-02,\n",
      "         -2.5381e-02, -3.1270e-02, -3.6570e-02, -3.9330e-02, -3.7300e-02,\n",
      "         -3.6810e-02, -1.7859e-02, -1.3515e-02, -3.0281e-04,  1.2910e-02,\n",
      "          4.9902e-03, -1.5675e-02,  1.8559e-02,  5.3182e-02,  5.2532e-02,\n",
      "          5.1298e-02,  5.0350e-02,  8.6125e-02,  1.0766e-01,  1.2435e-01,\n",
      "          1.2174e-01, -2.6532e-02,  9.3462e-04,  1.2388e-01],\n",
      "        [-2.3122e-02,  3.7434e-02,  6.5618e-02,  5.9172e-02,  2.8139e-02,\n",
      "         -2.7790e-03,  6.2891e-03,  1.5357e-02,  2.4425e-02,  3.3492e-02,\n",
      "          4.2231e-02,  9.5266e-03, -5.5039e-04, -1.0581e-02, -2.0612e-02,\n",
      "         -3.0642e-02, -4.0673e-02,  3.2095e-02,  8.3156e-02, -1.2266e-02,\n",
      "         -9.1844e-02, -1.0493e-01, -2.6627e-02,  3.7632e-02, -6.6270e-02,\n",
      "         -5.3801e-02, -4.1333e-02, -2.8866e-02, -1.6398e-02, -3.9304e-03,\n",
      "          8.5375e-03,  9.6942e-02,  5.5827e-02,  9.7639e-03, -7.5979e-02,\n",
      "         -3.6237e-02,  1.2749e-02, -5.2380e-03, -7.0419e-02, -2.4669e-02,\n",
      "          2.1241e-02,  8.0104e-02, -6.1659e-02, -4.5051e-02, -1.7112e-02,\n",
      "          1.8728e-02,  6.2466e-02,  1.0620e-01,  1.4994e-01,  1.9368e-01,\n",
      "          2.3742e-01,  2.5997e-01,  2.8001e-01,  3.0004e-01,  3.2050e-01,\n",
      "          3.4115e-01,  3.6414e-01,  3.8999e-01,  4.1336e-01,  4.3126e-01,\n",
      "          6.6015e-01,  9.4694e-01,  1.2337e+00,  1.5205e+00]], device='cuda:0')\n",
      "fc3.weight replacement complete\n"
     ]
    }
   ],
   "source": [
    "# prediction.mul_(2).sub_(1)\n",
    "\n",
    "index_tracker = 0\n",
    "with torch.no_grad():\n",
    "    for name, param in cppn1.named_parameters():\n",
    "        # print(name)\n",
    "        if name.endswith(\"fc3.weight\"):\n",
    "            # print(param) \n",
    "            # prediction.mul_()\n",
    "            temp_tensor = prediction[index_tracker:(index_tracker + param.numel())]\n",
    "            print(param.numel())\n",
    "            temp_tensor = torch.reshape(temp_tensor, param.shape)\n",
    "            print(temp_tensor)\n",
    "            param.data.copy_(temp_tensor)\n",
    "            # print(param.numel())\n",
    "            index_tracker += param.numel()\n",
    "    \n",
    "            print(f\"{name} replacement complete\")\n",
    "\n",
    "    torch.save(cppn1.state_dict(), \"Checkpoints/CPPNsquared_output.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI4M",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
