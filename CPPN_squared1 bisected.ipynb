{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from src.CPPN1 import CPPN1\n",
    "from src.CPPN1 import CPPN1training\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"CPPNsquared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "num_steps = 50000\n",
    "batch_size = 192\n",
    "learn_rate = 0.001\n",
    "momentum = 0.9\n",
    "num_channels = 3\n",
    "image_shape = (512, 644)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPPN1(\n",
      "  (fc1): Linear(in_features=2, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fce1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cppn1 = CPPN1()\n",
    "cppn1.load_state_dict = torch.load('Checkpoints/CPPN64.pt')\n",
    "print(cppn1)\n",
    "# feature maps trasfer learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(list(cppn1.children())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weights_initialized_randomly(model):\n",
    "#     for name, param in model.named_parameters():\n",
    "#         # Check if parameter is trainable and requires gradients\n",
    "#         if param.requires_grad:\n",
    "#             # If any parameter has non-zero values, it's not randomly initialized\n",
    "#             if torch.sum(param.data) != 0:\n",
    "#                 return False\n",
    "#     return True\n",
    "\n",
    "# print(weights_initialized_randomly(cppn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fce1.weight\n",
      "fce1.bias\n",
      "fc3.weight\n",
      "fc3.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in cppn1.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map spacial coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  1.,  0.],\n",
      "        [ 0.,  1.,  1.,  0.],\n",
      "        [ 0.,  2.,  1.,  0.],\n",
      "        [ 0.,  3.,  1.,  0.],\n",
      "        [ 0.,  4.,  1.,  0.],\n",
      "        [ 0.,  5.,  1.,  0.],\n",
      "        [ 0.,  6.,  1.,  0.],\n",
      "        [ 0.,  7.,  1.,  0.],\n",
      "        [ 0.,  8.,  1.,  0.],\n",
      "        [ 0.,  9.,  1.,  0.],\n",
      "        [ 0., 10.,  1.,  0.],\n",
      "        [ 0., 11.,  1.,  0.],\n",
      "        [ 0., 12.,  1.,  0.],\n",
      "        [ 0., 13.,  1.,  0.],\n",
      "        [ 0., 14.,  1.,  0.],\n",
      "        [ 0., 15.,  1.,  0.],\n",
      "        [ 0., 16.,  1.,  0.],\n",
      "        [ 0., 17.,  1.,  0.],\n",
      "        [ 0., 18.,  1.,  0.],\n",
      "        [ 0., 19.,  1.,  0.],\n",
      "        [ 0., 20.,  1.,  0.],\n",
      "        [ 0., 21.,  1.,  0.],\n",
      "        [ 0., 22.,  1.,  0.],\n",
      "        [ 0., 23.,  1.,  0.],\n",
      "        [ 0., 24.,  1.,  0.],\n",
      "        [ 0., 25.,  1.,  0.],\n",
      "        [ 0., 26.,  1.,  0.],\n",
      "        [ 0., 27.,  1.,  0.],\n",
      "        [ 0., 28.,  1.,  0.],\n",
      "        [ 0., 29.,  1.,  0.],\n",
      "        [ 0., 30.,  1.,  0.],\n",
      "        [ 0., 31.,  1.,  0.],\n",
      "        [ 0., 32.,  1.,  0.],\n",
      "        [ 0., 33.,  1.,  0.],\n",
      "        [ 0., 34.,  1.,  0.],\n",
      "        [ 0., 35.,  1.,  0.],\n",
      "        [ 0., 36.,  1.,  0.],\n",
      "        [ 0., 37.,  1.,  0.],\n",
      "        [ 0., 38.,  1.,  0.],\n",
      "        [ 0., 39.,  1.,  0.],\n",
      "        [ 0., 40.,  1.,  0.],\n",
      "        [ 0., 41.,  1.,  0.],\n",
      "        [ 0., 42.,  1.,  0.],\n",
      "        [ 0., 43.,  1.,  0.],\n",
      "        [ 0., 44.,  1.,  0.],\n",
      "        [ 0., 45.,  1.,  0.],\n",
      "        [ 0., 46.,  1.,  0.],\n",
      "        [ 0., 47.,  1.,  0.],\n",
      "        [ 0., 48.,  1.,  0.],\n",
      "        [ 0., 49.,  1.,  0.],\n",
      "        [ 0., 50.,  1.,  0.],\n",
      "        [ 0., 51.,  1.,  0.],\n",
      "        [ 0., 52.,  1.,  0.],\n",
      "        [ 0., 53.,  1.,  0.],\n",
      "        [ 0., 54.,  1.,  0.],\n",
      "        [ 0., 55.,  1.,  0.],\n",
      "        [ 0., 56.,  1.,  0.],\n",
      "        [ 0., 57.,  1.,  0.],\n",
      "        [ 0., 58.,  1.,  0.],\n",
      "        [ 0., 59.,  1.,  0.],\n",
      "        [ 0., 60.,  1.,  0.],\n",
      "        [ 0., 61.,  1.,  0.],\n",
      "        [ 0., 62.,  1.,  0.],\n",
      "        [ 0., 63.,  1.,  0.],\n",
      "        [ 0.,  0.,  1.,  1.],\n",
      "        [ 0.,  1.,  1.,  1.],\n",
      "        [ 0.,  2.,  1.,  1.],\n",
      "        [ 0.,  3.,  1.,  1.],\n",
      "        [ 0.,  4.,  1.,  1.],\n",
      "        [ 0.,  5.,  1.,  1.],\n",
      "        [ 0.,  6.,  1.,  1.],\n",
      "        [ 0.,  7.,  1.,  1.],\n",
      "        [ 0.,  8.,  1.,  1.],\n",
      "        [ 0.,  9.,  1.,  1.],\n",
      "        [ 0., 10.,  1.,  1.],\n",
      "        [ 0., 11.,  1.,  1.],\n",
      "        [ 0., 12.,  1.,  1.],\n",
      "        [ 0., 13.,  1.,  1.],\n",
      "        [ 0., 14.,  1.,  1.],\n",
      "        [ 0., 15.,  1.,  1.],\n",
      "        [ 0., 16.,  1.,  1.],\n",
      "        [ 0., 17.,  1.,  1.],\n",
      "        [ 0., 18.,  1.,  1.],\n",
      "        [ 0., 19.,  1.,  1.],\n",
      "        [ 0., 20.,  1.,  1.],\n",
      "        [ 0., 21.,  1.,  1.],\n",
      "        [ 0., 22.,  1.,  1.],\n",
      "        [ 0., 23.,  1.,  1.],\n",
      "        [ 0., 24.,  1.,  1.],\n",
      "        [ 0., 25.,  1.,  1.],\n",
      "        [ 0., 26.,  1.,  1.],\n",
      "        [ 0., 27.,  1.,  1.],\n",
      "        [ 0., 28.,  1.,  1.],\n",
      "        [ 0., 29.,  1.,  1.],\n",
      "        [ 0., 30.,  1.,  1.],\n",
      "        [ 0., 31.,  1.,  1.],\n",
      "        [ 0., 32.,  1.,  1.],\n",
      "        [ 0., 33.,  1.,  1.],\n",
      "        [ 0., 34.,  1.,  1.],\n",
      "        [ 0., 35.,  1.,  1.],\n",
      "        [ 0., 36.,  1.,  1.],\n",
      "        [ 0., 37.,  1.,  1.],\n",
      "        [ 0., 38.,  1.,  1.],\n",
      "        [ 0., 39.,  1.,  1.],\n",
      "        [ 0., 40.,  1.,  1.],\n",
      "        [ 0., 41.,  1.,  1.],\n",
      "        [ 0., 42.,  1.,  1.],\n",
      "        [ 0., 43.,  1.,  1.],\n",
      "        [ 0., 44.,  1.,  1.],\n",
      "        [ 0., 45.,  1.,  1.],\n",
      "        [ 0., 46.,  1.,  1.],\n",
      "        [ 0., 47.,  1.,  1.],\n",
      "        [ 0., 48.,  1.,  1.],\n",
      "        [ 0., 49.,  1.,  1.],\n",
      "        [ 0., 50.,  1.,  1.],\n",
      "        [ 0., 51.,  1.,  1.],\n",
      "        [ 0., 52.,  1.,  1.],\n",
      "        [ 0., 53.,  1.,  1.],\n",
      "        [ 0., 54.,  1.,  1.],\n",
      "        [ 0., 55.,  1.,  1.],\n",
      "        [ 0., 56.,  1.,  1.],\n",
      "        [ 0., 57.,  1.,  1.],\n",
      "        [ 0., 58.,  1.,  1.],\n",
      "        [ 0., 59.,  1.,  1.],\n",
      "        [ 0., 60.,  1.,  1.],\n",
      "        [ 0., 61.,  1.,  1.],\n",
      "        [ 0., 62.,  1.,  1.],\n",
      "        [ 0., 63.,  1.,  1.],\n",
      "        [ 0.,  0.,  1.,  2.],\n",
      "        [ 0.,  1.,  1.,  2.],\n",
      "        [ 0.,  2.,  1.,  2.],\n",
      "        [ 0.,  3.,  1.,  2.],\n",
      "        [ 0.,  4.,  1.,  2.],\n",
      "        [ 0.,  5.,  1.,  2.],\n",
      "        [ 0.,  6.,  1.,  2.],\n",
      "        [ 0.,  7.,  1.,  2.],\n",
      "        [ 0.,  8.,  1.,  2.],\n",
      "        [ 0.,  9.,  1.,  2.],\n",
      "        [ 0., 10.,  1.,  2.],\n",
      "        [ 0., 11.,  1.,  2.],\n",
      "        [ 0., 12.,  1.,  2.],\n",
      "        [ 0., 13.,  1.,  2.],\n",
      "        [ 0., 14.,  1.,  2.],\n",
      "        [ 0., 15.,  1.,  2.],\n",
      "        [ 0., 16.,  1.,  2.],\n",
      "        [ 0., 17.,  1.,  2.],\n",
      "        [ 0., 18.,  1.,  2.],\n",
      "        [ 0., 19.,  1.,  2.],\n",
      "        [ 0., 20.,  1.,  2.],\n",
      "        [ 0., 21.,  1.,  2.],\n",
      "        [ 0., 22.,  1.,  2.],\n",
      "        [ 0., 23.,  1.,  2.],\n",
      "        [ 0., 24.,  1.,  2.],\n",
      "        [ 0., 25.,  1.,  2.],\n",
      "        [ 0., 26.,  1.,  2.],\n",
      "        [ 0., 27.,  1.,  2.],\n",
      "        [ 0., 28.,  1.,  2.],\n",
      "        [ 0., 29.,  1.,  2.],\n",
      "        [ 0., 30.,  1.,  2.],\n",
      "        [ 0., 31.,  1.,  2.],\n",
      "        [ 0., 32.,  1.,  2.],\n",
      "        [ 0., 33.,  1.,  2.],\n",
      "        [ 0., 34.,  1.,  2.],\n",
      "        [ 0., 35.,  1.,  2.],\n",
      "        [ 0., 36.,  1.,  2.],\n",
      "        [ 0., 37.,  1.,  2.],\n",
      "        [ 0., 38.,  1.,  2.],\n",
      "        [ 0., 39.,  1.,  2.],\n",
      "        [ 0., 40.,  1.,  2.],\n",
      "        [ 0., 41.,  1.,  2.],\n",
      "        [ 0., 42.,  1.,  2.],\n",
      "        [ 0., 43.,  1.,  2.],\n",
      "        [ 0., 44.,  1.,  2.],\n",
      "        [ 0., 45.,  1.,  2.],\n",
      "        [ 0., 46.,  1.,  2.],\n",
      "        [ 0., 47.,  1.,  2.],\n",
      "        [ 0., 48.,  1.,  2.],\n",
      "        [ 0., 49.,  1.,  2.],\n",
      "        [ 0., 50.,  1.,  2.],\n",
      "        [ 0., 51.,  1.,  2.],\n",
      "        [ 0., 52.,  1.,  2.],\n",
      "        [ 0., 53.,  1.,  2.],\n",
      "        [ 0., 54.,  1.,  2.],\n",
      "        [ 0., 55.,  1.,  2.],\n",
      "        [ 0., 56.,  1.,  2.],\n",
      "        [ 0., 57.,  1.,  2.],\n",
      "        [ 0., 58.,  1.,  2.],\n",
      "        [ 0., 59.,  1.,  2.],\n",
      "        [ 0., 60.,  1.,  2.],\n",
      "        [ 0., 61.,  1.,  2.],\n",
      "        [ 0., 62.,  1.,  2.],\n",
      "        [ 0., 63.,  1.,  2.]], device='cuda:0')\n",
      "[[-1.0, -1.0, -0.5, -1.0], [-1.0, -0.9682539701461792, -0.5, -1.0], [-1.0, -0.9365079402923584, -0.5, -1.0], [-1.0, -0.9047619104385376, -0.5, -1.0], [-1.0, -0.8730158805847168, -0.5, -1.0], [-1.0, -0.841269850730896, -0.5, -1.0], [-1.0, -0.8095238208770752, -0.5, -1.0], [-1.0, -0.7777777910232544, -0.5, -1.0], [-1.0, -0.7460317611694336, -0.5, -1.0], [-1.0, -0.7142857313156128, -0.5, -1.0], [-1.0, -0.682539701461792, -0.5, -1.0], [-1.0, -0.6507936716079712, -0.5, -1.0], [-1.0, -0.6190476417541504, -0.5, -1.0], [-1.0, -0.5873016119003296, -0.5, -1.0], [-1.0, -0.5555555820465088, -0.5, -1.0], [-1.0, -0.523809552192688, -0.5, -1.0], [-1.0, -0.4920634627342224, -0.5, -1.0], [-1.0, -0.4603174328804016, -0.5, -1.0], [-1.0, -0.4285714030265808, -0.5, -1.0], [-1.0, -0.39682537317276, -0.5, -1.0], [-1.0, -0.3650793433189392, -0.5, -1.0], [-1.0, -0.3333333134651184, -0.5, -1.0], [-1.0, -0.3015872836112976, -0.5, -1.0], [-1.0, -0.2698412537574768, -0.5, -1.0], [-1.0, -0.238095223903656, -0.5, -1.0], [-1.0, -0.2063491940498352, -0.5, -1.0], [-1.0, -0.1746031641960144, -0.5, -1.0], [-1.0, -0.1428571343421936, -0.5, -1.0], [-1.0, -0.1111111044883728, -0.5, -1.0], [-1.0, -0.079365074634552, -0.5, -1.0], [-1.0, -0.0476190447807312, -0.5, -1.0], [-1.0, -0.0158730149269104, -0.5, -1.0], [-1.0, 0.015873074531555176, -0.5, -1.0], [-1.0, 0.04761910438537598, -0.5, -1.0], [-1.0, 0.07936513423919678, -0.5, -1.0], [-1.0, 0.11111116409301758, -0.5, -1.0], [-1.0, 0.14285719394683838, -0.5, -1.0], [-1.0, 0.17460322380065918, -0.5, -1.0], [-1.0, 0.20634925365447998, -0.5, -1.0], [-1.0, 0.23809528350830078, -0.5, -1.0], [-1.0, 0.2698413133621216, -0.5, -1.0], [-1.0, 0.3015873432159424, -0.5, -1.0], [-1.0, 0.3333333730697632, -0.5, -1.0], [-1.0, 0.365079402923584, -0.5, -1.0], [-1.0, 0.3968254327774048, -0.5, -1.0], [-1.0, 0.4285714626312256, -0.5, -1.0], [-1.0, 0.4603174924850464, -0.5, -1.0], [-1.0, 0.4920635223388672, -0.5, -1.0], [-1.0, 0.523809552192688, -0.5, -1.0], [-1.0, 0.5555555820465088, -0.5, -1.0], [-1.0, 0.5873016119003296, -0.5, -1.0], [-1.0, 0.6190476417541504, -0.5, -1.0], [-1.0, 0.6507936716079712, -0.5, -1.0], [-1.0, 0.682539701461792, -0.5, -1.0], [-1.0, 0.7142857313156128, -0.5, -1.0], [-1.0, 0.7460317611694336, -0.5, -1.0], [-1.0, 0.7777777910232544, -0.5, -1.0], [-1.0, 0.8095238208770752, -0.5, -1.0], [-1.0, 0.841269850730896, -0.5, -1.0], [-1.0, 0.8730158805847168, -0.5, -1.0], [-1.0, 0.9047619104385376, -0.5, -1.0], [-1.0, 0.9365079402923584, -0.5, -1.0], [-1.0, 0.9682539701461792, -0.5, -1.0], [-1.0, 1.0, -0.5, -1.0], [-1.0, -1.0, -0.5, 0.0], [-1.0, -0.9682539701461792, -0.5, 0.0], [-1.0, -0.9365079402923584, -0.5, 0.0], [-1.0, -0.9047619104385376, -0.5, 0.0], [-1.0, -0.8730158805847168, -0.5, 0.0], [-1.0, -0.841269850730896, -0.5, 0.0], [-1.0, -0.8095238208770752, -0.5, 0.0], [-1.0, -0.7777777910232544, -0.5, 0.0], [-1.0, -0.7460317611694336, -0.5, 0.0], [-1.0, -0.7142857313156128, -0.5, 0.0], [-1.0, -0.682539701461792, -0.5, 0.0], [-1.0, -0.6507936716079712, -0.5, 0.0], [-1.0, -0.6190476417541504, -0.5, 0.0], [-1.0, -0.5873016119003296, -0.5, 0.0], [-1.0, -0.5555555820465088, -0.5, 0.0], [-1.0, -0.523809552192688, -0.5, 0.0], [-1.0, -0.4920634627342224, -0.5, 0.0], [-1.0, -0.4603174328804016, -0.5, 0.0], [-1.0, -0.4285714030265808, -0.5, 0.0], [-1.0, -0.39682537317276, -0.5, 0.0], [-1.0, -0.3650793433189392, -0.5, 0.0], [-1.0, -0.3333333134651184, -0.5, 0.0], [-1.0, -0.3015872836112976, -0.5, 0.0], [-1.0, -0.2698412537574768, -0.5, 0.0], [-1.0, -0.238095223903656, -0.5, 0.0], [-1.0, -0.2063491940498352, -0.5, 0.0], [-1.0, -0.1746031641960144, -0.5, 0.0], [-1.0, -0.1428571343421936, -0.5, 0.0], [-1.0, -0.1111111044883728, -0.5, 0.0], [-1.0, -0.079365074634552, -0.5, 0.0], [-1.0, -0.0476190447807312, -0.5, 0.0], [-1.0, -0.0158730149269104, -0.5, 0.0], [-1.0, 0.015873074531555176, -0.5, 0.0], [-1.0, 0.04761910438537598, -0.5, 0.0], [-1.0, 0.07936513423919678, -0.5, 0.0], [-1.0, 0.11111116409301758, -0.5, 0.0], [-1.0, 0.14285719394683838, -0.5, 0.0], [-1.0, 0.17460322380065918, -0.5, 0.0], [-1.0, 0.20634925365447998, -0.5, 0.0], [-1.0, 0.23809528350830078, -0.5, 0.0], [-1.0, 0.2698413133621216, -0.5, 0.0], [-1.0, 0.3015873432159424, -0.5, 0.0], [-1.0, 0.3333333730697632, -0.5, 0.0], [-1.0, 0.365079402923584, -0.5, 0.0], [-1.0, 0.3968254327774048, -0.5, 0.0], [-1.0, 0.4285714626312256, -0.5, 0.0], [-1.0, 0.4603174924850464, -0.5, 0.0], [-1.0, 0.4920635223388672, -0.5, 0.0], [-1.0, 0.523809552192688, -0.5, 0.0], [-1.0, 0.5555555820465088, -0.5, 0.0], [-1.0, 0.5873016119003296, -0.5, 0.0], [-1.0, 0.6190476417541504, -0.5, 0.0], [-1.0, 0.6507936716079712, -0.5, 0.0], [-1.0, 0.682539701461792, -0.5, 0.0], [-1.0, 0.7142857313156128, -0.5, 0.0], [-1.0, 0.7460317611694336, -0.5, 0.0], [-1.0, 0.7777777910232544, -0.5, 0.0], [-1.0, 0.8095238208770752, -0.5, 0.0], [-1.0, 0.841269850730896, -0.5, 0.0], [-1.0, 0.8730158805847168, -0.5, 0.0], [-1.0, 0.9047619104385376, -0.5, 0.0], [-1.0, 0.9365079402923584, -0.5, 0.0], [-1.0, 0.9682539701461792, -0.5, 0.0], [-1.0, 1.0, -0.5, 0.0], [-1.0, -1.0, -0.5, 1.0], [-1.0, -0.9682539701461792, -0.5, 1.0], [-1.0, -0.9365079402923584, -0.5, 1.0], [-1.0, -0.9047619104385376, -0.5, 1.0], [-1.0, -0.8730158805847168, -0.5, 1.0], [-1.0, -0.841269850730896, -0.5, 1.0], [-1.0, -0.8095238208770752, -0.5, 1.0], [-1.0, -0.7777777910232544, -0.5, 1.0], [-1.0, -0.7460317611694336, -0.5, 1.0], [-1.0, -0.7142857313156128, -0.5, 1.0], [-1.0, -0.682539701461792, -0.5, 1.0], [-1.0, -0.6507936716079712, -0.5, 1.0], [-1.0, -0.6190476417541504, -0.5, 1.0], [-1.0, -0.5873016119003296, -0.5, 1.0], [-1.0, -0.5555555820465088, -0.5, 1.0], [-1.0, -0.523809552192688, -0.5, 1.0], [-1.0, -0.4920634627342224, -0.5, 1.0], [-1.0, -0.4603174328804016, -0.5, 1.0], [-1.0, -0.4285714030265808, -0.5, 1.0], [-1.0, -0.39682537317276, -0.5, 1.0], [-1.0, -0.3650793433189392, -0.5, 1.0], [-1.0, -0.3333333134651184, -0.5, 1.0], [-1.0, -0.3015872836112976, -0.5, 1.0], [-1.0, -0.2698412537574768, -0.5, 1.0], [-1.0, -0.238095223903656, -0.5, 1.0], [-1.0, -0.2063491940498352, -0.5, 1.0], [-1.0, -0.1746031641960144, -0.5, 1.0], [-1.0, -0.1428571343421936, -0.5, 1.0], [-1.0, -0.1111111044883728, -0.5, 1.0], [-1.0, -0.079365074634552, -0.5, 1.0], [-1.0, -0.0476190447807312, -0.5, 1.0], [-1.0, -0.0158730149269104, -0.5, 1.0], [-1.0, 0.015873074531555176, -0.5, 1.0], [-1.0, 0.04761910438537598, -0.5, 1.0], [-1.0, 0.07936513423919678, -0.5, 1.0], [-1.0, 0.11111116409301758, -0.5, 1.0], [-1.0, 0.14285719394683838, -0.5, 1.0], [-1.0, 0.17460322380065918, -0.5, 1.0], [-1.0, 0.20634925365447998, -0.5, 1.0], [-1.0, 0.23809528350830078, -0.5, 1.0], [-1.0, 0.2698413133621216, -0.5, 1.0], [-1.0, 0.3015873432159424, -0.5, 1.0], [-1.0, 0.3333333730697632, -0.5, 1.0], [-1.0, 0.365079402923584, -0.5, 1.0], [-1.0, 0.3968254327774048, -0.5, 1.0], [-1.0, 0.4285714626312256, -0.5, 1.0], [-1.0, 0.4603174924850464, -0.5, 1.0], [-1.0, 0.4920635223388672, -0.5, 1.0], [-1.0, 0.523809552192688, -0.5, 1.0], [-1.0, 0.5555555820465088, -0.5, 1.0], [-1.0, 0.5873016119003296, -0.5, 1.0], [-1.0, 0.6190476417541504, -0.5, 1.0], [-1.0, 0.6507936716079712, -0.5, 1.0], [-1.0, 0.682539701461792, -0.5, 1.0], [-1.0, 0.7142857313156128, -0.5, 1.0], [-1.0, 0.7460317611694336, -0.5, 1.0], [-1.0, 0.7777777910232544, -0.5, 1.0], [-1.0, 0.8095238208770752, -0.5, 1.0], [-1.0, 0.841269850730896, -0.5, 1.0], [-1.0, 0.8730158805847168, -0.5, 1.0], [-1.0, 0.9047619104385376, -0.5, 1.0], [-1.0, 0.9365079402923584, -0.5, 1.0], [-1.0, 0.9682539701461792, -0.5, 1.0], [-1.0, 1.0, -0.5, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "parameter_info = []\n",
    "fc1 = []\n",
    "full_coords = []\n",
    "full_weights = []\n",
    "layer_count = len(list(cppn1.children()))\n",
    "\n",
    "\n",
    "def normalize(tensor, axis):\n",
    "    if axis % 2 == 0:\n",
    "        max_vals = layer_count\n",
    "        min_vals = 0\n",
    "    else:\n",
    "        max_vals, _ = torch.max(tensor, dim=0)\n",
    "        min_vals, _ = torch.min(tensor, dim=0)\n",
    "\n",
    "    normalized_tensor = 2 * (tensor - min_vals) / (max_vals - min_vals) - 1\n",
    "    return normalized_tensor\n",
    "\n",
    "def spatial_coords(array, layer):\n",
    "\n",
    "    coords = []\n",
    "    row1 = []\n",
    "    row2 = []\n",
    "    for i in range(array.shape[0]):\n",
    "        row2.append([layer+1, i])\n",
    "    for i in range(array.shape[1]):\n",
    "        row1.append([layer, i])\n",
    "            \n",
    "    array = array.flatten(\"C\").tolist()\n",
    "    # print(array)\n",
    "    for i in row2:\n",
    "        for j in row1:\n",
    "            temp = []\n",
    "            temp.extend(j)\n",
    "            temp.extend(i)\n",
    "            coords.append((temp))\n",
    "    # coords_array = np.array(coords)\n",
    "    # coords_array.astype(int)\n",
    "    # output = np.column_stack((coords_array, array))\n",
    "\n",
    "    # print(len(output))\n",
    "    return coords, array\n",
    "            \n",
    "    # array.flatten()\n",
    "    # return np.stack((array, coords))\n",
    "\n",
    "index = 0\n",
    "for name, param in cppn1.named_parameters():\n",
    "    \n",
    "    # print(name)\n",
    "    if name.endswith(\"fc3.weight\"):\n",
    "        \n",
    "        # print(index)\n",
    "        # print(param)\n",
    "        temp_layer = param.detach().numpy() # need to learn more about gradients and why they are required\n",
    "        # print(temp_layer)\n",
    "\n",
    "        temp_coords, temp_weights = spatial_coords(temp_layer, index)\n",
    "        temp_coords = torch.tensor(temp_coords, device=device, dtype=torch.float32)\n",
    "        normal = temp_coords\n",
    "        print(temp_coords)\n",
    "        for i in range(4):\n",
    "            # print(i)\n",
    "            normal[:,i] = normalize(temp_coords[:, i], i)\n",
    "            # normal = torch.nan_to_num(normal, nan = 0)\n",
    "        if index == 3:\n",
    "            # print(temp_coords)\n",
    "            print(normal)\n",
    "            # print(normal)\n",
    "        full_coords.extend(normal.tolist())\n",
    "        full_weights.extend(temp_weights)\n",
    "\n",
    "        index += 1\n",
    "        # print(fc1.shape[0])\n",
    "\n",
    "print(full_coords)\n",
    "\n",
    "# print(full_weights)\n",
    "    \n",
    "# layer1_coords, layer1_weights = spatial_coords(fce1, 2)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize =(12,8))\n",
    "# ax.scatter(range(len(full_weights)), full_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up CPPN_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPPN_squared(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "      super(CPPN_squared, self).__init__()\n",
    "\n",
    "      self.fc1 = nn.Linear(4, 16)\n",
    "\n",
    "      self.fc2 = nn.Linear(16, 64)\n",
    "      self.fce1 = nn.Linear(64, 64)\n",
    "      self.fce2 = nn.Linear(64, 16)\n",
    "\n",
    "      self.fc3 = nn.Linear(16, 1)     \n",
    "\n",
    "    #   self.init_weights()\n",
    "      \n",
    "    # def init_weights(self):\n",
    "    #   for m in self.modules():\n",
    "    #       if isinstance(m, nn.Linear):\n",
    "    #           # Initialize weights using Xavier initialization\n",
    "    #           init.xavier_normal_(m.weight)\n",
    "    #           # Initialize biases to zeros\n",
    "    #           init.constant_(m.bias, 0)\n",
    "    \n",
    "    # defines forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        # x = torch.sin(x)\n",
    "        x = F.relu(x)\n",
    "        # x = F.tanh(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        # x = torch.sin(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fce1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fce2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        # returns the output of layer 3 after activation\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPPN_squared = CPPN_squared()\n",
    "# wandb.watch(CPPN_squared)\n",
    "CPPN_squared.to(device)\n",
    "CPPN_squared.requires_grad_()\n",
    "\n",
    "# optimiser = torch.optim.SGD(cppn.parameters(), lr=learn_rate, momentum=momentum)\n",
    "optimiser = torch.optim.Adam(CPPN_squared.parameters(), lr=learn_rate)\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "# criterion = nn.L1Loss(reduction = \"mean\")\n",
    "# criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_minus1_to_1(tensor):\n",
    "    min_vals, _ = torch.min(tensor, dim=0)\n",
    "    max_vals, _ = torch.max(tensor, dim=0)\n",
    "    normalized_tensor = 2 * (tensor - min_vals) / (max_vals - min_vals) - 1\n",
    "    return normalized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0125, -0.0439, -0.0229, -0.0695, -0.0824,  0.0758, -0.0440,  0.0070,\n",
      "        -0.0043,  0.0775, -0.0246,  0.0831,  0.0147,  0.0829, -0.0938,  0.0394,\n",
      "         0.1200, -0.0965,  0.1165,  0.1069, -0.0084,  0.1099, -0.1006, -0.1043,\n",
      "        -0.0017,  0.0199,  0.0057,  0.0245,  0.0380, -0.0528,  0.0457,  0.0469,\n",
      "         0.0251, -0.0182,  0.0145,  0.0475,  0.0837,  0.0188,  0.0035, -0.0932,\n",
      "         0.0720, -0.0046,  0.0771,  0.1146, -0.0373, -0.0588, -0.0412,  0.0645,\n",
      "        -0.0181, -0.1007, -0.1201,  0.1047, -0.0776,  0.0621,  0.1238,  0.0712,\n",
      "         0.0365,  0.0797,  0.0441, -0.0598, -0.0719,  0.0324,  0.0452, -0.0117,\n",
      "         0.0052, -0.0593, -0.0106, -0.1213, -0.1039, -0.0224,  0.0371, -0.0323,\n",
      "         0.0160,  0.0742, -0.0919, -0.0667,  0.0293,  0.0296,  0.0563, -0.1074,\n",
      "        -0.1248, -0.0590,  0.0316,  0.0806,  0.0331,  0.0988,  0.0101, -0.0622,\n",
      "         0.0202, -0.1062, -0.0048,  0.0276, -0.0394,  0.0051, -0.0279,  0.1194,\n",
      "        -0.0487, -0.0563, -0.0121, -0.0903, -0.0415, -0.0912, -0.0823, -0.0919,\n",
      "         0.0081, -0.0586, -0.0014,  0.0442,  0.0284,  0.0238, -0.0440, -0.0653,\n",
      "        -0.0567,  0.0329, -0.0242, -0.1082,  0.0608, -0.0946,  0.0730,  0.0106,\n",
      "         0.0124, -0.0663, -0.0511, -0.1032, -0.0815,  0.0006, -0.0217, -0.0678,\n",
      "         0.1111, -0.0377,  0.0908,  0.0083,  0.1059, -0.1152,  0.0951, -0.1137,\n",
      "         0.1212, -0.1246,  0.1016, -0.0105,  0.0480,  0.1197, -0.0403,  0.1240,\n",
      "        -0.0935,  0.0256,  0.0222, -0.0691, -0.0710,  0.1235, -0.0791, -0.0889,\n",
      "        -0.0422, -0.0124, -0.0019, -0.0992,  0.0235, -0.0986,  0.0608,  0.0522,\n",
      "         0.0040,  0.0901, -0.0714, -0.0988, -0.0106,  0.0043, -0.0472, -0.1064,\n",
      "         0.0500,  0.0947, -0.0319, -0.0841,  0.0440,  0.0477,  0.1101,  0.0506,\n",
      "        -0.0030,  0.0449, -0.0769,  0.0068, -0.1223, -0.0774,  0.0881,  0.0085,\n",
      "        -0.1020,  0.1073,  0.0522,  0.0564,  0.1146,  0.0485, -0.0581, -0.0299],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "normalized_coords_matrix = torch.tensor(full_coords, device=device, dtype=torch.float32)\n",
    "\n",
    "# Normalize the coordinates matrix along each column\n",
    "# normalized_coords_matrix = normalize_minus1_to_1(all_xy_coordinates)\n",
    "# print(normalized_coords_matrix)\n",
    "\n",
    "all_pixel_values = torch.tensor(full_weights, device=device, dtype=torch.float32)\n",
    "# all_pixel_values = (all_pixel_values + 1)/2\n",
    "# all_pixel_values = torch.unsqueeze(all_pixel_values, 0)\n",
    "print(all_pixel_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training and validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train, test = train_test_split(normalized_coords_matrix, test_size= 0.2, random_state=42)\n",
    "train_coords, val_coords, train_pixel_values, val_pixel_values = train_test_split(normalized_coords_matrix, all_pixel_values, test_size=0.1, random_state=42)\n",
    "# import math\n",
    "batch_size = int(batch_size * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0000, -1.0000, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.9683, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.9365, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.9048, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.8730, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.8413, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.8095, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.7778, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.7460, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.7143, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.6825, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.6508, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.6190, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.5873, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.5556, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.5238, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.4921, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.4603, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.4286, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.3968, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.3651, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.3333, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.3016, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.2698, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.2381, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.2063, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.1746, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.1429, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.1111, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.0794, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.0476, -0.5000, -1.0000],\n",
      "        [-1.0000, -0.0159, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.0159, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.0476, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.0794, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.1111, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.1429, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.1746, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.2063, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.2381, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.2698, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.3016, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.3333, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.3651, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.3968, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.4286, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.4603, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.4921, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.5238, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.5556, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.5873, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.6190, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.6508, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.6825, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.7143, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.7460, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.7778, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.8095, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.8413, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.8730, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.9048, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.9365, -0.5000, -1.0000],\n",
      "        [-1.0000,  0.9683, -0.5000, -1.0000],\n",
      "        [-1.0000,  1.0000, -0.5000, -1.0000],\n",
      "        [-1.0000, -1.0000, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.9683, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.9365, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.9048, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.8730, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.8413, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.8095, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.7778, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.7460, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.7143, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.6825, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.6508, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.6190, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.5873, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.5556, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.5238, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.4921, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.4603, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.4286, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.3968, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.3651, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.3333, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.3016, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.2698, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.2381, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.2063, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.1746, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.1429, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.1111, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.0794, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.0476, -0.5000,  0.0000],\n",
      "        [-1.0000, -0.0159, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.0159, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.0476, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.0794, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.1111, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.1429, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.1746, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.2063, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.2381, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.2698, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.3016, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.3333, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.3651, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.3968, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.4286, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.4603, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.4921, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.5238, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.5556, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.5873, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.6190, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.6508, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.6825, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.7143, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.7460, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.7778, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.8095, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.8413, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.8730, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.9048, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.9365, -0.5000,  0.0000],\n",
      "        [-1.0000,  0.9683, -0.5000,  0.0000],\n",
      "        [-1.0000,  1.0000, -0.5000,  0.0000],\n",
      "        [-1.0000, -1.0000, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.9683, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.9365, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.9048, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.8730, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.8413, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.8095, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.7778, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.7460, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.7143, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.6825, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.6508, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.6190, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.5873, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.5556, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.5238, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.4921, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.4603, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.4286, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.3968, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.3651, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.3333, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.3016, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.2698, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.2381, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.2063, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.1746, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.1429, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.1111, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.0794, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.0476, -0.5000,  1.0000],\n",
      "        [-1.0000, -0.0159, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.0159, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.0476, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.0794, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.1111, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.1429, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.1746, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.2063, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.2381, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.2698, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.3016, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.3333, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.3651, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.3968, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.4286, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.4603, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.4921, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.5238, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.5556, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.5873, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.6190, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.6508, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.6825, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.7143, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.7460, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.7778, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.8095, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.8413, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.8730, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.9048, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.9365, -0.5000,  1.0000],\n",
      "        [-1.0000,  0.9683, -0.5000,  1.0000],\n",
      "        [-1.0000,  1.0000, -0.5000,  1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(normalized_coords_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 0.214\n",
      "Validation - Step 0, loss 0.189\n",
      "step 5000, loss 30.157\n",
      "Validation - Step 5000, loss 0.005\n",
      "step 10000, loss 23.806\n",
      "Validation - Step 10000, loss 0.005\n",
      "step 15000, loss 23.635\n",
      "Validation - Step 15000, loss 0.005\n",
      "step 20000, loss 23.180\n",
      "Validation - Step 20000, loss 0.005\n",
      "step 25000, loss 23.806\n",
      "Validation - Step 25000, loss 0.005\n",
      "step 30000, loss 23.806\n",
      "Validation - Step 30000, loss 0.005\n",
      "step 35000, loss 23.806\n",
      "Validation - Step 35000, loss 0.005\n",
      "step 40000, loss 23.806\n",
      "Validation - Step 40000, loss 0.005\n",
      "step 45000, loss 23.806\n",
      "Validation - Step 45000, loss 0.005\n"
     ]
    }
   ],
   "source": [
    "num_coords = normalized_coords_matrix.shape[0]\n",
    "coord_indexes = list(range(0, num_coords))\n",
    "losses = []\n",
    "img_list = []\n",
    "running_loss = 0.0\n",
    "best_loss = 10000000\n",
    "best_val_loss = 10000000\n",
    "\n",
    "# training loop\n",
    "for i in range(num_steps):\n",
    "    optimiser.zero_grad()\n",
    "    CPPN_squared.zero_grad()\n",
    "\n",
    "    # Sample a random batch of indexes from the list coord_indexes\n",
    "    training_batch_indexes = torch.tensor(np.array(random.sample(range(0, train_coords.shape[0]), batch_size)))\n",
    "    \n",
    "    # Get batch of respective xy_coordiantes\n",
    "    training_coords_batch = normalized_coords_matrix[training_batch_indexes]\n",
    "    \n",
    "    # And respective pixel values \n",
    "    pixel_values_batch = train_pixel_values[training_batch_indexes]\n",
    "    pixel_values_batch = pixel_values_batch.unsqueeze(1)\n",
    "    \n",
    "    # Process data with model\n",
    "    approx_pixel_values = CPPN_squared(training_coords_batch)\n",
    "    \n",
    "    # Calculate and track loss function\n",
    "    loss = criterion(approx_pixel_values, pixel_values_batch)\n",
    "    running_loss += loss.item()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if i % 5000 == 0:\n",
    "        if running_loss < best_loss:\n",
    "            best_loss = running_loss\n",
    "            torch.save(CPPN_squared.state_dict(), 'Checkpoints/CPPN2model.pt')\n",
    "        print(f'step {i}, loss {running_loss:.3f}')\n",
    "        # wandb.log({\"loss\": loss.item()})\n",
    "        running_loss = 0.0\n",
    "\n",
    "        #validation loop\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            #should i iterate through them one by one or just do the whole thing?\n",
    "            # for i in range(val_coords.shape[0]):\n",
    "            #     val_output = CPPN_squared(val_coords[i])\n",
    "            #     val_loss += criterion(val_pixel_values[i], val_output.unsqueeze(0)).item()\n",
    "            val_output = CPPN_squared(val_coords)\n",
    "            val_loss += criterion(val_output,val_pixel_values.unsqueeze(1)).item()\n",
    "            # val_loss /= val_coords.shape[0]\n",
    "\n",
    "            # if val_loss < best_val_loss:\n",
    "            #     best_val_loss = val_loss\n",
    "            #     best_model_weights = CPPN_squared.state_dict()\n",
    "            #     torch.save(best_model_weights, 'best_CPPN2_weights.pt')\n",
    "                \n",
    "            print(f'Validation - Step {i}, loss {val_loss:.3f}')\n",
    "            # wandb.log({\"val_loss\": val_loss})\n",
    "\n",
    "            \n",
    "    #Update model\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    # wandb.log({\"final_weights\": CPPN_squared.state_dict()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.9451e-37, 1.8422e-32, 2.4149e-29, 4.9285e-30,\n",
      "        3.1707e-31, 4.3064e-33, 2.3123e-35, 1.2416e-37, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    torch.set_printoptions(profile=\"full\")\n",
    "    prediction = CPPN_squared(normalized_coords_matrix)\n",
    "    prediction = prediction.flatten(0)\n",
    "    # prediction = prediction * 2 - 1\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0125, -0.0439, -0.0229, -0.0695, -0.0824,  0.0758, -0.0440,  0.0070,\n",
      "        -0.0043,  0.0775, -0.0246,  0.0831,  0.0147,  0.0829, -0.0938,  0.0394,\n",
      "         0.1200, -0.0965,  0.1165,  0.1069, -0.0084,  0.1099, -0.1006, -0.1043,\n",
      "        -0.0017,  0.0199,  0.0057,  0.0245,  0.0380, -0.0528,  0.0457,  0.0469,\n",
      "         0.0251, -0.0182,  0.0145,  0.0475,  0.0837,  0.0188,  0.0035, -0.0932,\n",
      "         0.0720, -0.0046,  0.0771,  0.1146, -0.0373, -0.0588, -0.0412,  0.0645,\n",
      "        -0.0181, -0.1007, -0.1201,  0.1047, -0.0776,  0.0621,  0.1238,  0.0712,\n",
      "         0.0365,  0.0797,  0.0441, -0.0598, -0.0719,  0.0324,  0.0452, -0.0117,\n",
      "         0.0052, -0.0593, -0.0106, -0.1213, -0.1039, -0.0224,  0.0371, -0.0323,\n",
      "         0.0160,  0.0742, -0.0919, -0.0667,  0.0293,  0.0296,  0.0563, -0.1074,\n",
      "        -0.1248, -0.0590,  0.0316,  0.0806,  0.0331,  0.0988,  0.0101, -0.0622,\n",
      "         0.0202, -0.1062, -0.0048,  0.0276, -0.0394,  0.0051, -0.0279,  0.1194,\n",
      "        -0.0487, -0.0563, -0.0121, -0.0903, -0.0415, -0.0912, -0.0823, -0.0919,\n",
      "         0.0081, -0.0586, -0.0014,  0.0442,  0.0284,  0.0238, -0.0440, -0.0653,\n",
      "        -0.0567,  0.0329, -0.0242, -0.1082,  0.0608, -0.0946,  0.0730,  0.0106,\n",
      "         0.0124, -0.0663, -0.0511, -0.1032, -0.0815,  0.0006, -0.0217, -0.0678,\n",
      "         0.1111, -0.0377,  0.0908,  0.0083,  0.1059, -0.1152,  0.0951, -0.1137,\n",
      "         0.1212, -0.1246,  0.1016, -0.0105,  0.0480,  0.1197, -0.0403,  0.1240,\n",
      "        -0.0935,  0.0256,  0.0222, -0.0691, -0.0710,  0.1235, -0.0791, -0.0889,\n",
      "        -0.0422, -0.0124, -0.0019, -0.0992,  0.0235, -0.0986,  0.0608,  0.0522,\n",
      "         0.0040,  0.0901, -0.0714, -0.0988, -0.0106,  0.0043, -0.0472, -0.1064,\n",
      "         0.0500,  0.0947, -0.0319, -0.0841,  0.0440,  0.0477,  0.1101,  0.0506,\n",
      "        -0.0030,  0.0449, -0.0769,  0.0068, -0.1223, -0.0774,  0.0881,  0.0085,\n",
      "        -0.1020,  0.1073,  0.0522,  0.0564,  0.1146,  0.0485, -0.0581, -0.0299],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(all_pixel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'target')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharey=True, figsize = (15, 6))\n",
    "# ax[0].set_ylim([0.1, 0.9])\n",
    "x_values = np.arange(len(prediction.cpu().numpy()))\n",
    "\n",
    "ax[0].scatter(x_values, prediction.cpu().numpy(), marker='o', s=2)\n",
    "ax[0].set_title(\"prediction\")\n",
    "ax[1].scatter(x_values, all_pixel_values.cpu().numpy(), marker='o', s=2)\n",
    "ax[1].set_title(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.9451e-37, 1.8422e-32, 2.4149e-29, 4.9285e-30, 3.1707e-31, 4.3064e-33,\n",
      "         2.3123e-35, 1.2416e-37, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0')\n",
      "fc3.weight replacement complete\n"
     ]
    }
   ],
   "source": [
    "# prediction.mul_(2).sub_(1)\n",
    "\n",
    "index_tracker = 0\n",
    "with torch.no_grad():\n",
    "    for name, param in cppn1.named_parameters():\n",
    "        # print(name)\n",
    "        if name.endswith(\"fc3.weight\"):\n",
    "            # print(param) \n",
    "            # prediction.mul_()\n",
    "            temp_tensor = prediction[index_tracker:(index_tracker + param.numel())]\n",
    "            print(param.numel())\n",
    "            temp_tensor = torch.reshape(temp_tensor, param.shape)\n",
    "            print(temp_tensor)\n",
    "            param.data.copy_(temp_tensor)\n",
    "            # print(param.numel())\n",
    "            index_tracker += param.numel()\n",
    "    \n",
    "            print(f\"{name} replacement complete\")\n",
    "\n",
    "    torch.save(cppn1.state_dict(), \"Checkpoints/CPPNsquared_output.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI4M",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
